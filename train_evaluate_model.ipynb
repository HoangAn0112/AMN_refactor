{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate model using Scikit-learn and Keras wrapper "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------- model ----------------------------------------\n",
      "number of metabolites:  1877\n",
      "filtered measurements size:  1\n",
      "dataset file: ./Dataset/biolog_iML1515_EXP_UB.npz\n",
      "model type: AMNWt\n",
      "model medium bound: UB\n",
      "timestep: 4\n",
      "training set size (17400, 430) (17400, 1)\n",
      "training epochs: 50\n",
      "training regression: True\n",
      "training batch size: 7\n",
      "training validation iter: 0\n",
      "training early stopping: False\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from aMNWtModel import AMNWtModel\n",
    "from aMRNNModel import AMRNNModel\n",
    "\n",
    "\n",
    "model_class = AMRNNModel\n",
    "model_class = AMNWtModel\n",
    "\n",
    "seed = 10\n",
    "# np.random.seed(seed=seed)  \n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# dataset_file = \"./Dataset/IJN1463_EXP_UB_Anne.npz\"\n",
    "# objective=['BIOMASS_KT2440_WT3']\n",
    "\n",
    "# dataset_file = \"./Dataset/IJN1463_10_UB.npz\"\n",
    "# objective=['BIOMASS_KT2440_WT3']\n",
    "\n",
    "# dataset_file = \"./Dataset/e_coli_core_UB_100.npz\"\n",
    "# objective=['BIOMASS_Ecoli_core_w_GAM']\n",
    "# epoch = 200\n",
    "# batch_size = 7\n",
    "# uptake_max_index = None\n",
    "\n",
    "dataset_file = \"./Dataset/biolog_iML1515_EXP_UB.npz\"\n",
    "objective=['BIOMASS_Ec_iML1515_core_75p37M']\n",
    "epoch = 1 #20\n",
    "batch_size = 30\n",
    "uptake_max_index=151\n",
    "\n",
    "\n",
    "\n",
    "print(\"---------------------------------------- model ----------------------------------------\")\n",
    "model = model_class(dataset_file=dataset_file, \n",
    "                   objective=objective,\n",
    "                   timestep=4,\n",
    "                #    n_hidden=1, \n",
    "                   hidden_dim=50,\n",
    "                   epochs=50, \n",
    "                   verbose=True,\n",
    "                   batch_size=7,\n",
    "                   uptake_max_index = uptake_max_index)\n",
    "model.printout()\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler,MaxAbsScaler \n",
    "from tools import MaxScaler\n",
    "scaler= MaxScaler()\n",
    "model.train_test_split(test_size=0.1, random_state=seed)\n",
    "model.preprocess(scaler)\n",
    "model.preprocessing_for_specific_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([244.11587715, 244.32231021, 242.90950251, 238.71664691,\n",
       "        243.06635141]),\n",
       " 'score_time': array([27.58643961, 20.34151244, 27.91285682, 27.53911853, 30.4492178 ]),\n",
       " 'test_loss_constraint': array([0.00044196, 0.00039969, 0.00042471, 0.00053706, 0.0004263 ]),\n",
       " 'train_loss_constraint': array([0.00044196, 0.0003997 , 0.0004247 , 0.00053706, 0.0004263 ]),\n",
       " 'test_mse': array([0.11339866, 0.10475939, 0.10861337, 0.16975524, 0.10407544]),\n",
       " 'train_mse': array([0.11052044, 0.10287896, 0.10883499, 0.17306297, 0.10495039]),\n",
       " 'test_R2': array([-8.59873990e-02, -1.69030148e-04, -5.63728762e-02, -6.76422977e-01,\n",
       "        -2.16543083e-02]),\n",
       " 'train_R2': array([-0.0759675 , -0.00260751, -0.05543267, -0.67322491, -0.01536882])}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross validation\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "estimator= KerasRegressor(build_fn=model.build_model, \n",
    "                          epochs=epoch, \n",
    "                          batch_size=batch_size, \n",
    "                          verbose=0)\n",
    "\n",
    "scoring = {\"loss_constraint\":make_scorer(model.loss_constraint),\n",
    "           \"mse\":make_scorer(model.mse),\n",
    "           \"R2\":make_scorer(model.R2),\n",
    "           }\n",
    "\n",
    "\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "fit_params = {'callbacks': [callback]}\n",
    "fit_params = {}\n",
    "\n",
    "kfold= KFold(n_splits=5,shuffle=True, random_state=seed)\n",
    "\n",
    "results=cross_validate(estimator, \n",
    "                       model.X_train, \n",
    "                       model.Y_train, \n",
    "                       cv=kfold, \n",
    "                       n_jobs=5, \n",
    "                       scoring=scoring, \n",
    "                       fit_params=fit_params,\n",
    "                       return_train_score=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_loss_constraint</th>\n",
       "      <th>train_loss_constraint</th>\n",
       "      <th>test_mse</th>\n",
       "      <th>train_mse</th>\n",
       "      <th>test_R2</th>\n",
       "      <th>train_R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>242.626138</td>\n",
       "      <td>26.765829</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.120120</td>\n",
       "      <td>0.120050</td>\n",
       "      <td>-0.168121</td>\n",
       "      <td>-0.164520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.272363</td>\n",
       "      <td>3.789005</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.027994</td>\n",
       "      <td>0.029790</td>\n",
       "      <td>0.286035</td>\n",
       "      <td>0.285913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>238.716647</td>\n",
       "      <td>20.341512</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.104075</td>\n",
       "      <td>0.102879</td>\n",
       "      <td>-0.676423</td>\n",
       "      <td>-0.673225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>242.909503</td>\n",
       "      <td>27.539119</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.104759</td>\n",
       "      <td>0.104950</td>\n",
       "      <td>-0.085987</td>\n",
       "      <td>-0.075967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>243.066351</td>\n",
       "      <td>27.586440</td>\n",
       "      <td>0.000426</td>\n",
       "      <td>0.000426</td>\n",
       "      <td>0.108613</td>\n",
       "      <td>0.108835</td>\n",
       "      <td>-0.056373</td>\n",
       "      <td>-0.055433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>244.115877</td>\n",
       "      <td>27.912857</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.113399</td>\n",
       "      <td>0.110520</td>\n",
       "      <td>-0.021654</td>\n",
       "      <td>-0.015369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>244.322310</td>\n",
       "      <td>30.449218</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.169755</td>\n",
       "      <td>0.173063</td>\n",
       "      <td>-0.000169</td>\n",
       "      <td>-0.002608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         fit_time  score_time  test_loss_constraint  train_loss_constraint  \\\n",
       "count    5.000000    5.000000              5.000000               5.000000   \n",
       "mean   242.626138   26.765829              0.000446               0.000446   \n",
       "std      2.272363    3.789005              0.000053               0.000053   \n",
       "min    238.716647   20.341512              0.000400               0.000400   \n",
       "25%    242.909503   27.539119              0.000425               0.000425   \n",
       "50%    243.066351   27.586440              0.000426               0.000426   \n",
       "75%    244.115877   27.912857              0.000442               0.000442   \n",
       "max    244.322310   30.449218              0.000537               0.000537   \n",
       "\n",
       "       test_mse  train_mse   test_R2  train_R2  \n",
       "count  5.000000   5.000000  5.000000  5.000000  \n",
       "mean   0.120120   0.120050 -0.168121 -0.164520  \n",
       "std    0.027994   0.029790  0.286035  0.285913  \n",
       "min    0.104075   0.102879 -0.676423 -0.673225  \n",
       "25%    0.104759   0.104950 -0.085987 -0.075967  \n",
       "50%    0.108613   0.108835 -0.056373 -0.055433  \n",
       "75%    0.113399   0.110520 -0.021654 -0.015369  \n",
       "max    0.169755   0.173063 -0.000169 -0.002608  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AMRNN with 1 layer as RNNCell input\n",
    "# AMRNN with 2 layer as RNNCell input, hidden layer 50\n",
    "# AMNWt with 2 layer as RNNCell input hidden layer 500\n",
    "# AMRNN with 2 layer as RNNCell input, hidden layer 50\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(results)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 : -0.011620220954988492\n",
      "Q2 : -0.018134945292827664\n"
     ]
    }
   ],
   "source": [
    "AMNWt_model = model.build_model()\n",
    "history = AMNWt_model.fit(model.X_train, model.Y_train, epochs=epoch, batch_size=batch_size, verbose=0)\n",
    "\n",
    "print(\"R2 :\", model.R2(model.Y_train, AMNWt_model.predict(model.X_train)))\n",
    "print(\"Q2 :\", model.R2(model.Y_test, AMNWt_model.predict(model.X_test)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search for hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agiralt/anaconda3/envs/AMN/lib/python3.9/site-packages/sklearn/model_selection/_search.py:285: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "estimator= KerasRegressor(build_fn=model.build_model, \n",
    "                          epochs=epoch, \n",
    "                          batch_size=batch_size, \n",
    "                          verbose=0)\n",
    "\n",
    "distributions = dict(batch_size=[7,20],\n",
    "                     nb_epoch=[2,100],\n",
    "                    #  hidden_dim=[1,2],\n",
    "                     )\n",
    "\n",
    "scoring = {\"loss_constraint\":make_scorer(model.loss_constraint),\n",
    "           \"mse\":make_scorer(model.mse),\n",
    "           \"R2\":make_scorer(model.R2),\n",
    "           }\n",
    "\n",
    "clf = RandomizedSearchCV(estimator, distributions, random_state=0)\n",
    "search = clf.fit(model.X_test, model.Y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------- model ----------------------------------------\n",
      "number of metabolites:  72\n",
      "filtered measurements size:  1\n",
      "dataset file: ./Dataset/e_coli_core_UB_100.npz\n",
      "model type: AMNWt\n",
      "model medium bound: UB\n",
      "timestep: 4\n",
      "training set size (100, 20) (100, 1)\n",
      "training epochs: 50\n",
      "training regression: True\n",
      "training batch size: 7\n",
      "training validation iter: 0\n",
      "training early stopping: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 : 0.43442647328897727\n",
      "Q2 : 0.3337210888765758\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# from aMNWtModel import AMNWtModel, RNNCell\n",
    "# model_class = AMNWtModel\n",
    "# model_file = \"Models/AMNWt_model.keras\"\n",
    "\n",
    "uptake_max_index = -1\n",
    "\n",
    "from aMRNNModel import AMRNNModel, RNNCell\n",
    "model_class = AMRNNModel\n",
    "model_file = \"Models/AMRNN_model.keras\"\n",
    "\n",
    "\n",
    "seed = 10\n",
    "tf.random.set_seed(seed)\n",
    "dataset_file = \"./Dataset/e_coli_core_UB_100.npz\"\n",
    "objective=['BIOMASS_Ecoli_core_w_GAM']\n",
    "epoch = 200\n",
    "batch_size = 7\n",
    "\n",
    "\n",
    "# dataset_file = \"./Dataset/biolog_iML1515_EXP_UB.npz\"\n",
    "# objective=['BIOMASS_Ec_iML1515_core_75p37M']\n",
    "# epoch = 1 #20\n",
    "# batch_size = 30\n",
    "# uptake_max_index=151\n",
    "\n",
    "# Dataset plus model structure\n",
    "print(\"---------------------------------------- model ----------------------------------------\")\n",
    "model = model_class(dataset_file=dataset_file, \n",
    "                   objective=objective,\n",
    "                   timestep=4,\n",
    "                   hidden_dim=50,\n",
    "                   epochs=50, \n",
    "                   verbose=True,\n",
    "                   batch_size=7)\n",
    "model.printout()\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler,MaxAbsScaler \n",
    "from tools import MaxScaler\n",
    "scaler= MaxScaler()\n",
    "model.train_test_split(test_size=0.1, random_state=seed)\n",
    "model.preprocess(scaler)\n",
    "model.preprocessing_for_specific_model()\n",
    "\n",
    "batch_size = 7\n",
    "\n",
    "# Construct and train an AMNWt model\n",
    "AMNWt_model = model.build_model()\n",
    "history = AMNWt_model.fit(model.X_train, model.Y_train, epochs=epoch, batch_size=batch_size, verbose=0)\n",
    "\n",
    "print(\"R2 :\", model.R2(model.Y_train, AMNWt_model.predict(model.X_train)))\n",
    "print(\"Q2 :\", model.R2(model.Y_test, AMNWt_model.predict(model.X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 : 0.43442647328897727\n",
      "Q2 : 0.3337210888765758\n"
     ]
    }
   ],
   "source": [
    "from tools import custom_loss\n",
    "\n",
    "seed = 10\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# Recreate new model from config file, compile and train it. First test on config.\n",
    "config = AMNWt_model.get_config()\n",
    "AMNWt_model_= tf.keras.Model.from_config(config, custom_objects={\"RNNCell\":RNNCell})\n",
    "my_mse = custom_loss(model.S, model.P_out,model.P_in)\n",
    "AMNWt_model_.compile(loss=my_mse,optimizer='adam',metrics=[my_mse])\n",
    "history = AMNWt_model_.fit(model.X_train, model.Y_train, epochs=epoch, batch_size=batch_size, verbose=0)\n",
    "# \n",
    "print(\"R2 :\", model.R2(model.Y_train, AMNWt_model_.predict(model.X_train)))\n",
    "print(\"Q2 :\", model.R2(model.Y_test, AMNWt_model_.predict(model.X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the train AMNWt_model\n",
    "tf.keras.models.save_model(AMNWt_model,model_file, overwrite=True, save_format=None, save_traces=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 : 0.7781931445961526\n",
      "Q2 : 0.6904411610096228\n"
     ]
    }
   ],
   "source": [
    "from tools import custom_loss\n",
    "\n",
    "AMNWt_model_ = tf.keras.models.load_model(model_file, custom_objects={\"RNNCell\":RNNCell,\n",
    "                                                                               \"my_mse\":custom_loss(model.S, model.P_out,model.P_in)})\n",
    "\n",
    "\n",
    "history = AMNWt_model_.fit(model.X_train, model.Y_train, epochs=epoch, batch_size=batch_size, verbose=0)\n",
    "print(\"R2 :\", model.R2(model.Y_train, AMNWt_model_.predict(model.X_train)))\n",
    "print(\"Q2 :\", model.R2(model.Y_test, AMNWt_model_.predict(model.X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AMN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
