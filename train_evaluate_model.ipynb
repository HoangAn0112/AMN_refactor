{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate model using Scikit-learn and Keras wrapper "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------- model ----------------------------------------\n",
      "number of metabolites:  72\n",
      "filtered measurements size:  1\n",
      "dataset file: ./Dataset/e_coli_core_UB_100.npz\n",
      "model type: AMNWt\n",
      "model medium bound: UB\n",
      "timestep: 4\n",
      "training set size (100, 20) (100, 1)\n",
      "nbr hidden layer: 1\n",
      "hidden layer size: 50\n",
      "activation function: relu\n",
      "training epochs: 200\n",
      "training regression: True\n",
      "training droP_out: 0.25\n",
      "training batch size: 7\n",
      "training validation iter: 0\n",
      "training xfold: 5\n",
      "training early stopping: False\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from aMNWtModel import AMNWtModel\n",
    "\n",
    "\n",
    "seed = 10\n",
    "# np.random.seed(seed=seed)  \n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "print(\"---------------------------------------- model ----------------------------------------\")\n",
    "model = AMNWtModel(dataset_file=\"./Dataset/e_coli_core_UB_100.npz\", \n",
    "                   objective=['BIOMASS_Ecoli_core_w_GAM'],\n",
    "                   timestep=4,\n",
    "                   n_hidden=1,\n",
    "                   hidden_dim=50,\n",
    "                   epochs=200, \n",
    "                   xfold=5,\n",
    "                   verbose=True,\n",
    "                   batch_size=7)\n",
    "model.printout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-06 14:30:35.916988: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-06 14:30:35.918782: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 5. Tune using inter_op_parallelism_threads for best performance.\n",
      "2023-09-06 14:30:35.931471: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-06 14:30:35.932858: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 5. Tune using inter_op_parallelism_threads for best performance.\n",
      "2023-09-06 14:30:35.934935: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-06 14:30:35.936122: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-06 14:30:35.936258: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 5. Tune using inter_op_parallelism_threads for best performance.\n",
      "2023-09-06 14:30:35.937504: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 5. Tune using inter_op_parallelism_threads for best performance.\n",
      "2023-09-06 14:30:35.950408: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-06 14:30:35.952191: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 5. Tune using inter_op_parallelism_threads for best performance.\n",
      "WARNING:tensorflow:From /home/agiralt/anaconda3/envs/AMN/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:3633: sparse_mat_mul (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.linalg.matmul` instead\n",
      "WARNING:tensorflow:From /home/agiralt/anaconda3/envs/AMN/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:3633: sparse_mat_mul (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.linalg.matmul` instead\n",
      "WARNING:tensorflow:From /home/agiralt/anaconda3/envs/AMN/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:3633: sparse_mat_mul (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.linalg.matmul` instead\n",
      "WARNING:tensorflow:From /home/agiralt/anaconda3/envs/AMN/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:3633: sparse_mat_mul (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.linalg.matmul` instead\n",
      "WARNING:tensorflow:From /home/agiralt/anaconda3/envs/AMN/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:3633: sparse_mat_mul (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.linalg.matmul` instead\n",
      "2023-09-06 14:30:36.172364: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2023-09-06 14:30:36.187146: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2023-09-06 14:30:36.190346: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2023-09-06 14:30:36.194092: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2023-09-06 14:30:36.208041: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([47.76771736, 50.29535532, 45.03954649, 41.84195757, 50.68474698]),\n",
       " 'score_time': array([0.44260573, 0.43480444, 0.55104494, 0.5660553 , 0.36312604]),\n",
       " 'test_loss_constraint': array([0.00450187, 0.00430672, 0.00399788, 0.00527716, 0.00453078]),\n",
       " 'train_loss_constraint': array([0.00446677, 0.00447337, 0.00462127, 0.00428615, 0.00446572]),\n",
       " 'test_mse': array([0.00386203, 0.00369545, 0.00318019, 0.0045736 , 0.00377568]),\n",
       " 'train_mse': array([0.00372052, 0.00381115, 0.0038593 , 0.00358447, 0.00372554]),\n",
       " 'test_R2': array([0.88869158, 0.87925747, 0.89708276, 0.88448292, 0.91322344]),\n",
       " 'train_R2': array([0.90699752, 0.88847216, 0.91491   , 0.89693221, 0.90542304])}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler,MaxAbsScaler \n",
    "scaler= MinMaxScaler()\n",
    "model.train_test_split(test_size=0.1, random_state=seed)\n",
    "model.preprocess(scaler)\n",
    "model.preprocessing_for_specific_model()\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "estimator= KerasRegressor(build_fn=model.build_model, \n",
    "                          epochs=200, \n",
    "                          batch_size=7, \n",
    "                          verbose=0)\n",
    "\n",
    "scoring = {\"loss_constraint\":make_scorer(model.loss_constraint),\n",
    "           \"mse\":make_scorer(model.mse),\n",
    "           \"R2\":make_scorer(model.R2),\n",
    "           }\n",
    "\n",
    "# cross validation\n",
    "kfold= KFold(n_splits=5,shuffle=True, random_state=seed)\n",
    "results=cross_validate(estimator, \n",
    "                       model.X_train, \n",
    "                       model.Y_train, \n",
    "                       cv=kfold, \n",
    "                       n_jobs=5, \n",
    "                       scoring=scoring, \n",
    "                       return_train_score=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/agiralt/anaconda3/envs/AMN/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:3633: sparse_mat_mul (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.linalg.matmul` instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-06 14:31:27.054118: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-06 14:31:27.056414: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2023-09-06 14:31:27.447160: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.17247505486011505, 0.16161514818668365, 0.15130934119224548, 0.14054113626480103, 0.1288565993309021, 0.1159210130572319, 0.10125409066677094, 0.08521904051303864, 0.06943834573030472, 0.05616830661892891, 0.04603414982557297, 0.038592807948589325, 0.033017586916685104, 0.029195960611104965, 0.026295484974980354, 0.02395368181169033, 0.022071925923228264, 0.02051737532019615, 0.019198892638087273, 0.017907891422510147, 0.01686926744878292, 0.01584378443658352, 0.015039673075079918, 0.014252063818275928, 0.013558387756347656, 0.012966175563633442, 0.012391277588903904, 0.011881964281201363, 0.01143654715269804, 0.011024274863302708, 0.010630127973854542, 0.010285998694598675, 0.00992645975202322, 0.009652146138250828, 0.009348303079605103, 0.009087318554520607, 0.008842726238071918, 0.008627857081592083, 0.008419251069426537, 0.008231722749769688, 0.008057166822254658, 0.007944337092339993, 0.007832787930965424, 0.007602025289088488, 0.007464949507266283, 0.007358833681792021, 0.007243170402944088, 0.00712654460221529, 0.007017411757260561, 0.006918801926076412, 0.006835208274424076, 0.006753562483936548, 0.006650871597230434, 0.006565820425748825, 0.006502451375126839, 0.006447774823755026, 0.0063652037642896175, 0.006311366800218821, 0.006249476224184036, 0.006166074890643358, 0.00611199252307415, 0.0060653965920209885, 0.005999700166285038, 0.005978395696729422, 0.005910200532525778, 0.0058721150271594524, 0.0058097634464502335, 0.005769155919551849, 0.005741445813328028, 0.005687308497726917, 0.005652081221342087, 0.005624363198876381, 0.005587267689406872, 0.0055357287637889385, 0.00551554886624217, 0.005478364415466785, 0.005456718150526285, 0.0054019358940422535, 0.0053625511936843395, 0.00535724638029933, 0.00530336145311594, 0.005275373347103596, 0.005250914022326469, 0.005243103485554457, 0.005194454919546843, 0.0051659513264894485, 0.005139871966093779, 0.005119475536048412, 0.005114485044032335, 0.005069375969469547, 0.00504425261169672, 0.005017814692109823, 0.005004487466067076, 0.004988175816833973, 0.004942284431308508, 0.0049165887758135796, 0.004890976473689079, 0.004870214033871889, 0.004848347045481205, 0.0048218099400401115, 0.004839660599827766, 0.004831541795283556, 0.004784753546118736, 0.004754840862005949, 0.0047449772246181965, 0.0047119539231061935, 0.004700342658907175, 0.004674587864428759, 0.004645995330065489, 0.004645186476409435, 0.004610844887793064, 0.004600163083523512, 0.0045896065421402454, 0.004583931528031826, 0.004549493547528982, 0.004522624425590038, 0.004499088041484356, 0.004482024349272251, 0.004475221503525972, 0.004452429711818695, 0.004444689489901066, 0.004419341217726469, 0.004401626996695995, 0.00439869612455368, 0.004378800746053457, 0.004357603378593922, 0.004330637399107218, 0.004309636540710926, 0.0042954240925610065, 0.00429010484367609, 0.004263826180249453, 0.004251505713909864, 0.004225433338433504, 0.0042237830348312855, 0.004207265563309193, 0.004195304587483406, 0.004189041443169117, 0.004173748195171356, 0.004150139167904854, 0.004128351341933012, 0.004109758883714676, 0.004090678412467241, 0.004092182498425245, 0.004087206907570362, 0.0040626428090035915, 0.004041653126478195, 0.004020560998469591, 0.003998477943241596, 0.003987591713666916, 0.003984036855399609, 0.003961408510804176, 0.003939033020287752, 0.003951772581785917, 0.00392681872472167, 0.00389429135248065, 0.0038934850599616766, 0.003867911407724023, 0.0038560894317924976, 0.003837837837636471, 0.003832925111055374, 0.0038132492918521166, 0.0037913769483566284, 0.0037767833564430475, 0.003760692896321416, 0.003747985465452075, 0.003744940273463726, 0.0037207347340881824, 0.0037159095518290997, 0.003705276409164071, 0.0037115775048732758, 0.003686130279675126, 0.003651942126452923, 0.0036444985307753086, 0.0036244946531951427, 0.00362950237467885, 0.0036083508748561144, 0.0035944762639701366, 0.0035783201456069946, 0.003557045478373766, 0.003549124812707305, 0.0035342921037226915, 0.0035222198348492384, 0.003500081365928054, 0.0034891648683696985, 0.0034658911172300577, 0.0034509252291172743, 0.00344182550907135, 0.003434461774304509, 0.0034238407388329506, 0.0034062734339386225, 0.003395766718313098, 0.003375052707269788, 0.0033576369751244783, 0.0033434368669986725, 0.003334201406687498, 0.003321221098303795, 0.003302185330539942, 0.0032960057724267244, 0.0032834080047905445, 0.0032747513614594936]\n",
      "0.9319160347295824\n",
      "0.8632603247881695\n"
     ]
    }
   ],
   "source": [
    "estimator= KerasRegressor(build_fn=model.build_model, \n",
    "                          epochs=200, \n",
    "                          batch_size=7, \n",
    "                          verbose=0)\n",
    "\n",
    "history = estimator.fit(model.X_train, model.Y_train)\n",
    "print(history.history[\"mse\"])\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "y_pred = estimator.predict(model.X_train)\n",
    "y_true = model.Y_train\n",
    "y_p = y_pred[:,:y_true.shape[1]]\n",
    "R2 = r2_score(y_true, y_p, multioutput='variance_weighted')\n",
    "print(R2)\n",
    "\n",
    "\n",
    "y_pred = estimator.predict(model.X_test)\n",
    "y_true = model.Y_test\n",
    "y_p = y_pred[:,:y_true.shape[1]]\n",
    "Q2 = r2_score(y_true, y_p, multioutput='variance_weighted')\n",
    "print(Q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AMN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
