{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Run AMN_Wt model on all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------- model ----------------------------------------\n",
      "number of metabolites:  72\n",
      "filtered measurements size:  1\n",
      "dataset file: ./Dataset/e_coli_core_UB_100.npz\n",
      "model type: AMNWt\n",
      "model scaler: 1.0\n",
      "model medium bound: UB\n",
      "timestep: 4\n",
      "training set size (100, 20) (100, 1)\n",
      "nbr hidden layer: 1\n",
      "hidden layer size: 50\n",
      "activation function: relu\n",
      "training epochs: 200\n",
      "training regression: True\n",
      "training learn rate: 0.01\n",
      "training droP_out: 0.25\n",
      "training batch size: 7\n",
      "training validation iter: 0\n",
      "training xfold: 5\n",
      "training early stopping: False\n",
      "---------------------------------------- train and evaluate ----------------------------------------\n",
      "train = 0.94 test = 0.93 loss-train = 0.004192 loss-test = 0.004219\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from aMNWtModel import AMNWtModel\n",
    "from tools import printout\n",
    "\n",
    "seed = 10\n",
    "np.random.seed(seed=seed)  \n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "print(\"---------------------------------------- model ----------------------------------------\")\n",
    "model = AMNWtModel(dataset_file=\"./Dataset/e_coli_core_UB_100.npz\", \n",
    "                   objective=['BIOMASS_Ecoli_core_w_GAM'],\n",
    "                   timestep=4,\n",
    "                   n_hidden=1,\n",
    "                   hidden_dim=50,\n",
    "                   scaler=True,\n",
    "                   train_rate=1e-2,\n",
    "                   epochs=200, \n",
    "                   xfold=5,\n",
    "                   verbose=True,\n",
    "                   batch_size=7)\n",
    "\n",
    "model.train_test_split(test_size=0.1, random_state=seed)\n",
    "model.printout()\n",
    "\n",
    "print(\"---------------------------------------- train and evaluate ----------------------------------------\")\n",
    "start_time = time.time()\n",
    "_, stats, _ = model.train_evaluate(verbose=False)\n",
    "reservoir = model\n",
    "delta_time = time.time() - start_time\n",
    "\n",
    "print(\"---------------------------------------- printing cross-validation results ----------------------------------------\")\n",
    "reservoir_name = \"e_coli_core_UB_50_AMN_Wt\"\n",
    "stats.printout(reservoir_name, delta_time)\n",
    "\n",
    "# reservoir.save(\"./Reservoir/e_coli_core_UB_50_AMN_Wt\")\n",
    "# reservoir.printout()\n",
    "\n",
    "print(\"---------------------------------------- evaluate model on test set ----------------------------------------\")\n",
    "\n",
    "start_time = time.time()\n",
    "## Strange two first lines, investigate\n",
    "reservoir.X, reservoir.Y = model.X_test, model.Y_test\n",
    "X, Y = reservoir.model_input(model.X_test, model.Y_test, verbose=False)\n",
    "pred, obj, loss = reservoir.evaluate_model(X, Y, verbose=False)\n",
    "delta_time = time.time() - start_time\n",
    "printout('Test set', delta_time, obj, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------- model ----------------------------------------\n",
      "number of metabolites:  72\n",
      "filtered measurements size:  1\n",
      "dataset file: ./Dataset/e_coli_core_UB.npz\n",
      "model type: AMNWt\n",
      "model scaler: 1.0\n",
      "model medium bound: UB\n",
      "timestep: 4\n",
      "training set size (1000, 20) (1000, 1)\n",
      "nbr hidden layer: 1\n",
      "hidden layer size: 50\n",
      "activation function: relu\n",
      "training epochs: 20\n",
      "training regression: True\n",
      "training learn rate: 0.01\n",
      "training droP_out: 0.25\n",
      "training batch size: 7\n",
      "training validation iter: 0\n",
      "training xfold: 5\n",
      "training early stopping: False\n",
      "---------------------------------------- train and evaluate ----------------------------------------\n",
      "WARNING:tensorflow:From /home/agiralt/anaconda3/envs/AMN/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:3633: sparse_mat_mul (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.linalg.matmul` instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-24 11:50:12.442833: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-24 11:50:12.444327: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2023-08-24 11:50:12.820010: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train = 0.95 test = 0.96 loss-train = 0.004603 loss-test = 0.004677\n",
      "train = 0.96 test = 0.96 loss-train = 0.004758 loss-test = 0.004760\n",
      "train = 0.94 test = 0.93 loss-train = 0.004356 loss-test = 0.004264\n",
      "train = 0.95 test = 0.94 loss-train = 0.004296 loss-test = 0.004455\n",
      "train = 0.97 test = 0.96 loss-train = 0.004050 loss-test = 0.003941\n",
      "---------------------------------------- printing cross-validation results ----------------------------------------\n",
      "Stats for e_coli_core_UB_50_AMN_Wt CPU-time 150.6262\n",
      "R2 = 0.9514 (+/- 0.0108) Constraint = 0.0044 (+/- 0.0002)\n",
      "Q2 = 0.9509 (+/- 0.0114) Constraint = 0.0044 (+/- 0.0003)\n",
      "---------------------------------------- evaluate model on test set ----------------------------------------\n",
      "Stats for Test set CPU-time 0.1100\n",
      "R2 = 0.9649 Constraint = 0.0041\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from aMNWtModel import AMNWtModel\n",
    "from tools import printout\n",
    "\n",
    "seed = 10\n",
    "np.random.seed(seed=seed)  \n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "print(\"---------------------------------------- model ----------------------------------------\")\n",
    "model = AMNWtModel(dataset_file=\"./Dataset/e_coli_core_UB.npz\", \n",
    "                   objective=['BIOMASS_Ecoli_core_w_GAM'],\n",
    "                   timestep=4,\n",
    "                   n_hidden=1,\n",
    "                   hidden_dim=50,\n",
    "                   scaler=True,\n",
    "                   train_rate=1e-2,\n",
    "                   epochs=20, \n",
    "                   xfold=5,\n",
    "                   verbose=True,\n",
    "                   batch_size=7)\n",
    "\n",
    "model.train_test_split(test_size=0.1, random_state=seed)\n",
    "model.printout()\n",
    "\n",
    "print(\"---------------------------------------- train and evaluate ----------------------------------------\")\n",
    "start_time = time.time()\n",
    "_, stats, _ = model.train_evaluate(verbose=False)\n",
    "reservoir = model\n",
    "delta_time = time.time() - start_time\n",
    "\n",
    "print(\"---------------------------------------- printing cross-validation results ----------------------------------------\")\n",
    "reservoir_name = \"e_coli_core_UB_50_AMN_Wt\"\n",
    "stats.printout(reservoir_name, delta_time)\n",
    "\n",
    "# reservoir.save(\"./Reservoir/e_coli_core_UB_50_AMN_Wt\")\n",
    "# reservoir.printout()\n",
    "\n",
    "print(\"---------------------------------------- evaluate model on test set ----------------------------------------\")\n",
    "\n",
    "start_time = time.time()\n",
    "## Strange two first lines, investigate\n",
    "reservoir.X, reservoir.Y = model.X_test, model.Y_test\n",
    "X, Y = reservoir.model_input(model.X_test, model.Y_test, verbose=False)\n",
    "pred, obj, loss = reservoir.evaluate_model(X, Y, verbose=False)\n",
    "delta_time = time.time() - start_time\n",
    "printout('Test set', delta_time, obj, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------- model ----------------------------------------\n",
      "number of metabolites:  72\n",
      "filtered measurements size:  1\n",
      "dataset file: ./Dataset/e_coli_core_EB.npz\n",
      "model type: AMNWt\n",
      "model scaler: 1.0\n",
      "model medium bound: EB\n",
      "timestep: 4\n",
      "training set size (1000, 20) (1000, 1)\n",
      "nbr hidden layer: 1\n",
      "hidden layer size: 50\n",
      "activation function: relu\n",
      "training epochs: 50\n",
      "training regression: True\n",
      "training learn rate: 0.01\n",
      "training droP_out: 0.25\n",
      "training batch size: 7\n",
      "training validation iter: 0\n",
      "training xfold: 5\n",
      "training early stopping: False\n",
      "---------------------------------------- train and evaluate ----------------------------------------\n",
      "WARNING:tensorflow:From /home/agiralt/anaconda3/envs/AMN/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:3633: sparse_mat_mul (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.linalg.matmul` instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-24 11:12:41.214794: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-24 11:12:41.217826: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2023-08-24 11:12:41.601591: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['rnn/rnn_cell/bias_Vi:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['rnn/rnn_cell/bias_Vi:0'] when minimizing the loss.\n",
      "train = 0.77 test = 0.76 loss-train = 0.002621 loss-test = 0.002593\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['rnn_1/rnn_cell_1/bias_Vi:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['rnn_1/rnn_cell_1/bias_Vi:0'] when minimizing the loss.\n",
      "train = 0.73 test = 0.75 loss-train = 0.002674 loss-test = 0.002725\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['rnn_2/rnn_cell_2/bias_Vi:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['rnn_2/rnn_cell_2/bias_Vi:0'] when minimizing the loss.\n",
      "train = 0.71 test = 0.71 loss-train = 0.002851 loss-test = 0.002731\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['rnn_3/rnn_cell_3/bias_Vi:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['rnn_3/rnn_cell_3/bias_Vi:0'] when minimizing the loss.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/agiralt/Documents/AMN/Factorisation_AMN/test_all_datasets.ipynb Cell 10\u001b[0m in \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/agiralt/Documents/AMN/Factorisation_AMN/test_all_datasets.ipynb#W3sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m---------------------------------------- train and evaluate ----------------------------------------\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/agiralt/Documents/AMN/Factorisation_AMN/test_all_datasets.ipynb#W3sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/agiralt/Documents/AMN/Factorisation_AMN/test_all_datasets.ipynb#W3sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m _, stats, _ \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtrain_evaluate(verbose\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/agiralt/Documents/AMN/Factorisation_AMN/test_all_datasets.ipynb#W3sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m reservoir \u001b[39m=\u001b[39m model\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/agiralt/Documents/AMN/Factorisation_AMN/test_all_datasets.ipynb#W3sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m delta_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/Documents/AMN/Factorisation_AMN/neuralModel.py:144\u001b[0m, in \u001b[0;36mNeuralModel.train_evaluate\u001b[0;34m(self, verbose)\u001b[0m\n\u001b[1;32m    142\u001b[0m Net \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(\u001b[39mself\u001b[39m)\n\u001b[1;32m    143\u001b[0m Net\u001b[39m.\u001b[39mset_model(verbose\u001b[39m=\u001b[39mverbose)\n\u001b[0;32m--> 144\u001b[0m y_test_pred, new_stats, history \u001b[39m=\u001b[39m Net\u001b[39m.\u001b[39;49mtrain_model(X[train], \n\u001b[1;32m    145\u001b[0m                                                   Y[train], \n\u001b[1;32m    146\u001b[0m                                                   X[test], \n\u001b[1;32m    147\u001b[0m                                                   Y[test], verbose\u001b[39m=\u001b[39;49mverbose)\n\u001b[1;32m    148\u001b[0m stats\u001b[39m.\u001b[39mupdate(new_stats)\n\u001b[1;32m    150\u001b[0m \u001b[39m# Fill the prediction set for this test fold\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/AMN/Factorisation_AMN/neuralModel.py:176\u001b[0m, in \u001b[0;36mNeuralModel.train_model\u001b[0;34m(self, X_train, Y_train, X_test, Y_test, verbose)\u001b[0m\n\u001b[1;32m    173\u001b[0m callbacks \u001b[39m=\u001b[39m [es] \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mearly_stopping \u001b[39melse\u001b[39;00m []\n\u001b[1;32m    175\u001b[0m \u001b[39m# fit\u001b[39;00m\n\u001b[0;32m--> 176\u001b[0m history \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mfit(X_train,\n\u001b[1;32m    177\u001b[0m                          Y_train,\n\u001b[1;32m    178\u001b[0m                          validation_data\u001b[39m=\u001b[39;49m(X_test, Y_test),\n\u001b[1;32m    179\u001b[0m                          epochs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepochs,\n\u001b[1;32m    180\u001b[0m                          batch_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_size, \n\u001b[1;32m    181\u001b[0m                          callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    182\u001b[0m                          verbose\u001b[39m=\u001b[39;49mverbose)\n\u001b[1;32m    184\u001b[0m \u001b[39m# evaluate\u001b[39;00m\n\u001b[1;32m    185\u001b[0m _, o_train, l_train \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluate_model(X_train, Y_train, verbose\u001b[39m=\u001b[39mverbose)\n",
      "File \u001b[0;32m~/anaconda3/envs/AMN/lib/python3.9/site-packages/keras/engine/training.py:1184\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1177\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1178\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1179\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   1180\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   1181\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   1182\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1183\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1184\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1185\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1186\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/AMN/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:885\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    882\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    884\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 885\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    887\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    888\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/AMN/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:917\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    914\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    915\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 917\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    918\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    919\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    920\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    921\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/AMN/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3039\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3036\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   3037\u001b[0m   (graph_function,\n\u001b[1;32m   3038\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   3040\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/AMN/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1963\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1960\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1961\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1962\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1963\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1964\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1965\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m     args,\n\u001b[1;32m   1967\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1968\u001b[0m     executing_eagerly)\n\u001b[1;32m   1969\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/AMN/lib/python3.9/site-packages/tensorflow/python/eager/function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    590\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 591\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    592\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    593\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    594\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    595\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    596\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    597\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    598\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    599\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    600\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    603\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    604\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/anaconda3/envs/AMN/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 59\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     60\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     62\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from aMNWtModel import AMNWtModel\n",
    "from tools import printout\n",
    "\n",
    "seed = 10\n",
    "np.random.seed(seed=seed)  \n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "print(\"---------------------------------------- model ----------------------------------------\")\n",
    "model = AMNWtModel(dataset_file=\"./Dataset/e_coli_core_EB.npz\", \n",
    "                   objective=['BIOMASS_Ecoli_core_w_GAM'],\n",
    "                   timestep=4,\n",
    "                   n_hidden=1,\n",
    "                   hidden_dim=50,\n",
    "                   scaler=True,\n",
    "                   train_rate=1e-2,\n",
    "                   epochs=50, \n",
    "                   xfold=5,\n",
    "                   verbose=True,\n",
    "                   batch_size=7)\n",
    "\n",
    "model.train_test_split(test_size=0.1, random_state=seed)\n",
    "model.printout()\n",
    "\n",
    "print(\"---------------------------------------- train and evaluate ----------------------------------------\")\n",
    "start_time = time.time()\n",
    "_, stats, _ = model.train_evaluate(verbose=False)\n",
    "reservoir = model\n",
    "delta_time = time.time() - start_time\n",
    "\n",
    "print(\"---------------------------------------- printing cross-validation results ----------------------------------------\")\n",
    "reservoir_name = \"e_coli_core_UB_50_AMN_Wt\"\n",
    "stats.printout(reservoir_name, delta_time)\n",
    "\n",
    "# reservoir.save(\"./Reservoir/e_coli_core_UB_50_AMN_Wt\")\n",
    "# reservoir.printout()\n",
    "\n",
    "print(\"---------------------------------------- evaluate model on test set ----------------------------------------\")\n",
    "\n",
    "start_time = time.time()\n",
    "## Strange two first lines, investigate\n",
    "reservoir.X, reservoir.Y = model.X_test, model.Y_test\n",
    "X, Y = reservoir.model_input(model.X_test, model.Y_test, verbose=False)\n",
    "pred, obj, loss = reservoir.evaluate_model(X, Y, verbose=False)\n",
    "delta_time = time.time() - start_time\n",
    "printout('Test set', delta_time, obj, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------- model ----------------------------------------\n",
      "number of metabolites:  1617\n",
      "filtered measurements size:  1\n",
      "dataset file: ./Dataset/IJN1463_10_UB.npz\n",
      "model type: AMNWt\n",
      "model scaler: 1.0\n",
      "model medium bound: UB\n",
      "timestep: 4\n",
      "training set size (4860, 196) (4860, 1)\n",
      "nbr hidden layer: 1\n",
      "hidden layer size: 50\n",
      "activation function: relu\n",
      "training epochs: 20\n",
      "training regression: True\n",
      "training learn rate: 0.01\n",
      "training droP_out: 0.25\n",
      "training batch size: 20\n",
      "training validation iter: 0\n",
      "training xfold: 5\n",
      "training early stopping: False\n",
      "---------------------------------------- train and evaluate ----------------------------------------\n",
      "train = 0.79 test = 0.78 loss-train = 0.000279 loss-test = 0.000288\n",
      "train = 0.79 test = 0.78 loss-train = 0.000327 loss-test = 0.000343\n",
      "train = 0.79 test = 0.78 loss-train = 0.000277 loss-test = 0.000287\n",
      "train = 0.80 test = 0.76 loss-train = 0.000319 loss-test = 0.000339\n",
      "train = 0.79 test = 0.78 loss-train = 0.000145 loss-test = 0.000135\n",
      "---------------------------------------- printing cross-validation results ----------------------------------------\n",
      "Stats for e_coli_core_UB_50_AMN_Wt CPU-time 3437.3509\n",
      "R2 = 0.7927 (+/- 0.0025) Constraint = 0.0003 (+/- 0.0001)\n",
      "Q2 = 0.7757 (+/- 0.0087) Constraint = 0.0003 (+/- 0.0001)\n",
      "---------------------------------------- evaluate model on test set ----------------------------------------\n",
      "Stats for Test set CPU-time 1.6971\n",
      "R2 = 0.7887 Constraint = 0.0003\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from aMNWtModel import AMNWtModel\n",
    "from tools import printout\n",
    "\n",
    "seed = 10\n",
    "np.random.seed(seed=seed)  \n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "print(\"---------------------------------------- model ----------------------------------------\")\n",
    "model = AMNWtModel(dataset_file=\"./Dataset/IJN1463_10_UB.npz\", \n",
    "                   objective=['BIOMASS_KT2440_WT3'],\n",
    "                   timestep=4,\n",
    "                   n_hidden=1,\n",
    "                   hidden_dim=50,\n",
    "                   scaler=True,\n",
    "                   train_rate=1e-2,\n",
    "                   epochs=20, \n",
    "                   xfold=5,\n",
    "                   verbose=True,\n",
    "                   batch_size=20) \n",
    "\n",
    "model.train_test_split(test_size=0.1, random_state=seed)\n",
    "model.printout()\n",
    "\n",
    "print(\"---------------------------------------- train and evaluate ----------------------------------------\")\n",
    "start_time = time.time()\n",
    "_, stats, _ = model.train_evaluate(verbose=False)\n",
    "reservoir = model\n",
    "delta_time = time.time() - start_time\n",
    "\n",
    "print(\"---------------------------------------- printing cross-validation results ----------------------------------------\")\n",
    "reservoir_name = \"e_coli_core_UB_50_AMN_Wt\"\n",
    "stats.printout(reservoir_name, delta_time)\n",
    "\n",
    "# reservoir.save(\"./Reservoir/e_coli_core_UB_50_AMN_Wt\")\n",
    "# reservoir.printout()\n",
    "\n",
    "print(\"---------------------------------------- evaluate model on test set ----------------------------------------\")\n",
    "\n",
    "start_time = time.time()\n",
    "## Strange two first lines, investigate\n",
    "reservoir.X, reservoir.Y = model.X_test, model.Y_test\n",
    "X, Y = reservoir.model_input(model.X_test, model.Y_test, verbose=False)\n",
    "pred, obj, loss = reservoir.evaluate_model(X, Y, verbose=False)\n",
    "delta_time = time.time() - start_time\n",
    "printout('Test set', delta_time, obj, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------- model ----------------------------------------\n",
      "number of metabolites:  1617\n",
      "filtered measurements size:  1\n",
      "dataset file: ./Dataset/IJN1463_10_UB.npz\n",
      "model type: AMNWt\n",
      "model scaler: 1.0\n",
      "model medium bound: UB\n",
      "timestep: 4\n",
      "training set size (4860, 196) (4860, 1)\n",
      "nbr hidden layer: 1\n",
      "hidden layer size: 30\n",
      "activation function: relu\n",
      "training epochs: 20\n",
      "training regression: True\n",
      "training learn rate: 0.01\n",
      "training droP_out: 0.25\n",
      "training batch size: 30\n",
      "training validation iter: 0\n",
      "training xfold: 5\n",
      "training early stopping: False\n",
      "---------------------------------------- train and evaluate ----------------------------------------\n",
      "train = 0.75 test = 0.75 loss-train = 0.000342 loss-test = 0.000356\n",
      "train = 0.79 test = 0.78 loss-train = 0.000289 loss-test = 0.000300\n",
      "train = 0.79 test = 0.78 loss-train = 0.000300 loss-test = 0.000310\n",
      "train = 0.78 test = 0.75 loss-train = 0.000354 loss-test = 0.000374\n",
      "train = 0.78 test = 0.77 loss-train = 0.000259 loss-test = 0.000241\n",
      "---------------------------------------- printing cross-validation results ----------------------------------------\n",
      "Stats for e_coli_core_UB_50_AMN_Wt CPU-time 2449.9351\n",
      "R2 = 0.7804 (+/- 0.0137) Constraint = 0.0003 (+/- 0.0000)\n",
      "Q2 = 0.7644 (+/- 0.0152) Constraint = 0.0003 (+/- 0.0000)\n",
      "---------------------------------------- evaluate model on test set ----------------------------------------\n",
      "Stats for Test set CPU-time 1.6876\n",
      "R2 = 0.7812 Constraint = 0.0003\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from aMNWtModel import AMNWtModel\n",
    "from tools import printout\n",
    "\n",
    "seed = 10\n",
    "np.random.seed(seed=seed)  \n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "print(\"---------------------------------------- model ----------------------------------------\")\n",
    "model = AMNWtModel(dataset_file=\"./Dataset/IJN1463_10_UB.npz\", \n",
    "                   objective=['BIOMASS_KT2440_WT3'],\n",
    "                   timestep=4,\n",
    "                   n_hidden=1,\n",
    "                   hidden_dim=30,\n",
    "                   scaler=True,\n",
    "                   train_rate=1e-2,\n",
    "                   epochs=20, \n",
    "                   xfold=5,\n",
    "                   verbose=True,\n",
    "                   batch_size=30) \n",
    "\n",
    "model.train_test_split(test_size=0.1, random_state=seed)\n",
    "model.printout()\n",
    "\n",
    "print(\"---------------------------------------- train and evaluate ----------------------------------------\")\n",
    "start_time = time.time()\n",
    "_, stats, _ = model.train_evaluate(verbose=False)\n",
    "reservoir = model\n",
    "delta_time = time.time() - start_time\n",
    "\n",
    "print(\"---------------------------------------- printing cross-validation results ----------------------------------------\")\n",
    "reservoir_name = \"e_coli_core_UB_50_AMN_Wt\"\n",
    "stats.printout(reservoir_name, delta_time)\n",
    "\n",
    "# reservoir.save(\"./Reservoir/e_coli_core_UB_50_AMN_Wt\")\n",
    "# reservoir.printout()\n",
    "\n",
    "print(\"---------------------------------------- evaluate model on test set ----------------------------------------\")\n",
    "\n",
    "start_time = time.time()\n",
    "## Strange two first lines, investigate\n",
    "reservoir.X, reservoir.Y = model.X_test, model.Y_test\n",
    "X, Y = reservoir.model_input(model.X_test, model.Y_test, verbose=False)\n",
    "pred, obj, loss = reservoir.evaluate_model(X, Y, verbose=False)\n",
    "delta_time = time.time() - start_time\n",
    "printout('Test set', delta_time, obj, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------- model ----------------------------------------\n",
      "number of metabolites:  1080\n",
      "filtered measurements size:  1\n",
      "dataset file: ./Dataset/iML1515_EXP_UB.npz\n",
      "model type: AMNWt\n",
      "model scaler: 1.0\n",
      "model medium bound: UB\n",
      "timestep: 4\n",
      "training set size (110, 38) (110, 1)\n",
      "nbr hidden layer: 1\n",
      "hidden layer size: 50\n",
      "activation function: relu\n",
      "training epochs: 200\n",
      "training regression: True\n",
      "training learn rate: 0.01\n",
      "training droP_out: 0.25\n",
      "training batch size: 7\n",
      "training validation iter: 0\n",
      "training xfold: 5\n",
      "training early stopping: False\n",
      "---------------------------------------- train and evaluate ----------------------------------------\n",
      "WARNING:tensorflow:From /home/agiralt/anaconda3/envs/AMN/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:3633: sparse_mat_mul (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.linalg.matmul` instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-24 10:37:28.645711: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-24 10:37:28.647698: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2023-08-24 10:37:29.095551: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train = 0.05 test = 0.04 loss-train = 0.000478 loss-test = 0.000481\n",
      "train = -1.06 test = -0.86 loss-train = 0.000812 loss-test = 0.000727\n",
      "train = 0.81 test = 0.83 loss-train = 0.000831 loss-test = 0.000865\n",
      "train = 0.53 test = 0.03 loss-train = 0.000131 loss-test = 0.000118\n",
      "train = 0.79 test = 0.59 loss-train = 0.000102 loss-test = 0.000100\n",
      "---------------------------------------- printing cross-validation results ----------------------------------------\n",
      "Stats for e_coli_core_UB_50_AMN_Wt CPU-time 830.8492\n",
      "R2 = 0.2273 (+/- 0.6983) Constraint = 0.0005 (+/- 0.0003)\n",
      "Q2 = 0.1264 (+/- 0.5813) Constraint = 0.0005 (+/- 0.0003)\n",
      "---------------------------------------- evaluate model on test set ----------------------------------------\n",
      "Stats for Test set CPU-time 0.1032\n",
      "R2 = 0.8444 Constraint = 0.0008\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from aMNWtModel import AMNWtModel\n",
    "from tools import printout\n",
    "\n",
    "seed = 5\n",
    "np.random.seed(seed=seed)  \n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "print(\"---------------------------------------- model ----------------------------------------\")\n",
    "model = AMNWtModel(dataset_file=\"./Dataset/iML1515_EXP_UB.npz\", \n",
    "                   objective=['BIOMASS_Ec_iML1515_core_75p37M'],\n",
    "                   timestep=4,\n",
    "                   n_hidden=1,\n",
    "                   hidden_dim=50,\n",
    "                   scaler=True,\n",
    "                   train_rate=1e-2,\n",
    "                   epochs=200, \n",
    "                   xfold=5,\n",
    "                   verbose=True,\n",
    "                   batch_size=7)\n",
    "\n",
    "model.train_test_split(test_size=0.1, random_state=seed)\n",
    "model.printout()\n",
    "\n",
    "print(\"---------------------------------------- train and evaluate ----------------------------------------\")\n",
    "start_time = time.time()\n",
    "_, stats, _ = model.train_evaluate(verbose=False)\n",
    "reservoir = model\n",
    "delta_time = time.time() - start_time\n",
    "\n",
    "print(\"---------------------------------------- printing cross-validation results ----------------------------------------\")\n",
    "reservoir_name = \"e_coli_core_UB_50_AMN_Wt\"\n",
    "stats.printout(reservoir_name, delta_time)\n",
    "\n",
    "# reservoir.save(\"./Reservoir/e_coli_core_UB_50_AMN_Wt\")\n",
    "# reservoir.printout()\n",
    "\n",
    "print(\"---------------------------------------- evaluate model on test set ----------------------------------------\")\n",
    "\n",
    "start_time = time.time()\n",
    "## Strange two first lines, investigate\n",
    "reservoir.X, reservoir.Y = model.X_test, model.Y_test\n",
    "X, Y = reservoir.model_input(model.X_test, model.Y_test, verbose=False)\n",
    "pred, obj, loss = reservoir.evaluate_model(X, Y, verbose=False)\n",
    "delta_time = time.time() - start_time\n",
    "printout('Test set', delta_time, obj, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------- model ----------------------------------------\n",
      "number of metabolites:  2153\n",
      "filtered measurements size:  1\n",
      "dataset file: ./Dataset/IJN1463_EXP_UB_Anne.npz\n",
      "model type: AMNWt\n",
      "model scaler: 1.0\n",
      "model medium bound: UB\n",
      "timestep: 4\n",
      "training set size (243, 196) (243, 1)\n",
      "nbr hidden layer: 1\n",
      "hidden layer size: 50\n",
      "activation function: relu\n",
      "training epochs: 200\n",
      "training regression: True\n",
      "training learn rate: 0.01\n",
      "training droP_out: 0.25\n",
      "training batch size: 7\n",
      "training validation iter: 0\n",
      "training xfold: 5\n",
      "training early stopping: False\n",
      "---------------------------------------- train and evaluate ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-24 20:36:56.320089: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-24 20:36:56.322094: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/agiralt/anaconda3/envs/AMN/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:3633: sparse_mat_mul (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.linalg.matmul` instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-24 20:36:57.032672: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train = 0.78 test = -0.16 loss-train = 0.000103 loss-test = 0.000061\n",
      "train = 0.81 test = -0.28 loss-train = 0.000005 loss-test = 0.000003\n",
      "train = 0.85 test = -0.20 loss-train = 0.000037 loss-test = 0.000025\n",
      "train = 0.84 test = -0.00 loss-train = 0.000013 loss-test = 0.000013\n",
      "train = 0.84 test = -0.61 loss-train = 0.000034 loss-test = 0.000020\n",
      "---------------------------------------- printing cross-validation results ----------------------------------------\n",
      "Stats for e_coli_core_UB_50_AMN_Wt CPU-time 10678.2079\n",
      "R2 = 0.8249 (+/- 0.0247) Constraint = 0.0000 (+/- 0.0000)\n",
      "Q2 = -0.2489 (+/- 0.2004) Constraint = 0.0000 (+/- 0.0000)\n",
      "---------------------------------------- evaluate model on test set ----------------------------------------\n",
      "Stats for Test set CPU-time 0.3354\n",
      "R2 = -0.4994 Constraint = 0.0000\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from aMNWtModel import AMNWtModel\n",
    "from tools import printout\n",
    "\n",
    "seed = 5\n",
    "np.random.seed(seed=seed)  \n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "print(\"---------------------------------------- model ----------------------------------------\")\n",
    "model = AMNWtModel(dataset_file=\"./Dataset/IJN1463_EXP_UB_Anne.npz\", \n",
    "                   objective=['BIOMASS_KT2440_WT3'],\n",
    "                   timestep=4,\n",
    "                   n_hidden=1,\n",
    "                   hidden_dim=50,\n",
    "                   scaler=True,\n",
    "                   train_rate=1e-2,\n",
    "                   epochs=200, \n",
    "                   xfold=5,\n",
    "                   verbose=True,\n",
    "                   batch_size=7)\n",
    "\n",
    "model.train_test_split(test_size=0.1, random_state=seed)\n",
    "model.printout()\n",
    "\n",
    "print(\"---------------------------------------- train and evaluate ----------------------------------------\")\n",
    "start_time = time.time()\n",
    "_, stats, _ = model.train_evaluate(verbose=False)\n",
    "reservoir = model\n",
    "delta_time = time.time() - start_time\n",
    "\n",
    "print(\"---------------------------------------- printing cross-validation results ----------------------------------------\")\n",
    "reservoir_name = \"e_coli_core_UB_50_AMN_Wt\"\n",
    "stats.printout(reservoir_name, delta_time)\n",
    "\n",
    "# reservoir.save(\"./Reservoir/e_coli_core_UB_50_AMN_Wt\")\n",
    "# reservoir.printout()\n",
    "\n",
    "print(\"---------------------------------------- evaluate model on test set ----------------------------------------\")\n",
    "\n",
    "start_time = time.time()\n",
    "## Strange two first lines, investigate\n",
    "reservoir.X, reservoir.Y = model.X_test, model.Y_test\n",
    "X, Y = reservoir.model_input(model.X_test, model.Y_test, verbose=False)\n",
    "pred, obj, loss = reservoir.evaluate_model(X, Y, verbose=False)\n",
    "delta_time = time.time() - start_time\n",
    "printout('Test set', delta_time, obj, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------- model ----------------------------------------\n",
      "number of metabolites:  1877\n",
      "filtered measurements size:  1\n",
      "dataset file: ./Dataset/iML1515_EXP_paul_UB.npz\n",
      "model type: AMNWt\n",
      "model scaler: 1.0\n",
      "model medium bound: UB\n",
      "timestep: 4\n",
      "training set size (186, 49) (186, 1)\n",
      "nbr hidden layer: 1\n",
      "hidden layer size: 50\n",
      "activation function: relu\n",
      "training epochs: 200\n",
      "training regression: True\n",
      "training learn rate: 0.01\n",
      "training droP_out: 0.25\n",
      "training batch size: 7\n",
      "training validation iter: 0\n",
      "training xfold: 5\n",
      "training early stopping: False\n",
      "---------------------------------------- train and evaluate ----------------------------------------\n",
      "train = 0.87 test = 0.84 loss-train = 0.000062 loss-test = 0.000068\n",
      "train = 0.78 test = 0.82 loss-train = 0.000015 loss-test = 0.000014\n",
      "train = 0.39 test = 0.30 loss-train = 0.000114 loss-test = 0.000124\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/agiralt/Documents/AMN/Factorisation_AMN/test_all_datasets.ipynb Cell 9\u001b[0m in \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/agiralt/Documents/AMN/Factorisation_AMN/test_all_datasets.ipynb#X32sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m---------------------------------------- train and evaluate ----------------------------------------\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/agiralt/Documents/AMN/Factorisation_AMN/test_all_datasets.ipynb#X32sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/agiralt/Documents/AMN/Factorisation_AMN/test_all_datasets.ipynb#X32sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m _, stats, _ \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtrain_evaluate(verbose\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/agiralt/Documents/AMN/Factorisation_AMN/test_all_datasets.ipynb#X32sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m reservoir \u001b[39m=\u001b[39m model\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/agiralt/Documents/AMN/Factorisation_AMN/test_all_datasets.ipynb#X32sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m delta_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/Documents/AMN/Factorisation_AMN/neuralModel.py:144\u001b[0m, in \u001b[0;36mNeuralModel.train_evaluate\u001b[0;34m(self, verbose)\u001b[0m\n\u001b[1;32m    142\u001b[0m Net \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(\u001b[39mself\u001b[39m)\n\u001b[1;32m    143\u001b[0m Net\u001b[39m.\u001b[39mset_model(verbose\u001b[39m=\u001b[39mverbose)\n\u001b[0;32m--> 144\u001b[0m y_test_pred, new_stats, history \u001b[39m=\u001b[39m Net\u001b[39m.\u001b[39;49mtrain_model(X[train], \n\u001b[1;32m    145\u001b[0m                                                   Y[train], \n\u001b[1;32m    146\u001b[0m                                                   X[test], \n\u001b[1;32m    147\u001b[0m                                                   Y[test], verbose\u001b[39m=\u001b[39;49mverbose)\n\u001b[1;32m    148\u001b[0m stats\u001b[39m.\u001b[39mupdate(new_stats)\n\u001b[1;32m    150\u001b[0m \u001b[39m# Fill the prediction set for this test fold\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/AMN/Factorisation_AMN/neuralModel.py:176\u001b[0m, in \u001b[0;36mNeuralModel.train_model\u001b[0;34m(self, X_train, Y_train, X_test, Y_test, verbose)\u001b[0m\n\u001b[1;32m    173\u001b[0m callbacks \u001b[39m=\u001b[39m [es] \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mearly_stopping \u001b[39melse\u001b[39;00m []\n\u001b[1;32m    175\u001b[0m \u001b[39m# fit\u001b[39;00m\n\u001b[0;32m--> 176\u001b[0m history \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mfit(X_train,\n\u001b[1;32m    177\u001b[0m                          Y_train,\n\u001b[1;32m    178\u001b[0m                          validation_data\u001b[39m=\u001b[39;49m(X_test, Y_test),\n\u001b[1;32m    179\u001b[0m                          epochs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepochs,\n\u001b[1;32m    180\u001b[0m                          batch_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_size, \n\u001b[1;32m    181\u001b[0m                          callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    182\u001b[0m                          verbose\u001b[39m=\u001b[39;49mverbose)\n\u001b[1;32m    184\u001b[0m \u001b[39m# evaluate\u001b[39;00m\n\u001b[1;32m    185\u001b[0m _, o_train, l_train \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluate_model(X_train, Y_train, verbose\u001b[39m=\u001b[39mverbose)\n",
      "File \u001b[0;32m~/anaconda3/envs/AMN/lib/python3.9/site-packages/keras/engine/training.py:1184\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1177\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1178\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1179\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   1180\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   1181\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   1182\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1183\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1184\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1185\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1186\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/AMN/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:885\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    882\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    884\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 885\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    887\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    888\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/AMN/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:917\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    914\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    915\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 917\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    918\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    919\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    920\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    921\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/AMN/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3039\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3036\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   3037\u001b[0m   (graph_function,\n\u001b[1;32m   3038\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   3040\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/AMN/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1963\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1960\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1961\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1962\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1963\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1964\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1965\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m     args,\n\u001b[1;32m   1967\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1968\u001b[0m     executing_eagerly)\n\u001b[1;32m   1969\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/AMN/lib/python3.9/site-packages/tensorflow/python/eager/function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    590\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 591\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    592\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    593\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    594\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    595\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    596\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    597\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    598\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    599\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    600\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    603\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    604\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/anaconda3/envs/AMN/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 59\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     60\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     62\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from aMNWtModel import AMNWtModel\n",
    "from tools import printout\n",
    "\n",
    "seed = 10\n",
    "np.random.seed(seed=seed)  \n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "print(\"---------------------------------------- model ----------------------------------------\")\n",
    "model = AMNWtModel(dataset_file=\"./Dataset/iML1515_EXP_paul_UB.npz\", \n",
    "                   objective=['BIOMASS_Ec_iML1515_core_75p37M'],\n",
    "                   timestep=4,\n",
    "                   n_hidden=1,\n",
    "                   hidden_dim=50,\n",
    "                   scaler=True,\n",
    "                   train_rate=1e-2,\n",
    "                   epochs=200, \n",
    "                   xfold=5,\n",
    "                   verbose=True,\n",
    "                   batch_size=7)\n",
    "\n",
    "model.train_test_split(test_size=0.1, random_state=seed)\n",
    "model.printout()\n",
    "\n",
    "print(\"---------------------------------------- train and evaluate ----------------------------------------\")\n",
    "start_time = time.time()\n",
    "_, stats, _ = model.train_evaluate(verbose=False)\n",
    "reservoir = model\n",
    "delta_time = time.time() - start_time\n",
    "\n",
    "print(\"---------------------------------------- printing cross-validation results ----------------------------------------\")\n",
    "reservoir_name = \"e_coli_core_UB_50_AMN_Wt\"\n",
    "stats.printout(reservoir_name, delta_time)\n",
    "\n",
    "# reservoir.save(\"./Reservoir/e_coli_core_UB_50_AMN_Wt\")\n",
    "# reservoir.printout()\n",
    "\n",
    "print(\"---------------------------------------- evaluate model on test set ----------------------------------------\")\n",
    "\n",
    "start_time = time.time()\n",
    "## Strange two first lines, investigate\n",
    "reservoir.X, reservoir.Y = model.X_test, model.Y_test\n",
    "X, Y = reservoir.model_input(model.X_test, model.Y_test, verbose=False)\n",
    "pred, obj, loss = reservoir.evaluate_model(X, Y, verbose=False)\n",
    "delta_time = time.time() - start_time\n",
    "printout('Test set', delta_time, obj, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AMN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
