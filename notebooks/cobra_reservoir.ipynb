{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AMN-resevoir to improve cobra prediction\n",
    "\n",
    "Here we attempt to improve the prediction of cobra solver on experimental data. The input commonly used in cobra is the concentration of compounds in the media, as an approximation of uptake fluxes of metabolism. We try here to improve the prediction of cobra here by finding a more accurate uptake fluxes estimation.\n",
    "We use an AMNWt model, trained on data simulated by cobra to mimic the behavior of cobra. All weight of this model are freezed after training. A part of the input fluxes is considered as essential in medium to obtain growth remains unchanged but the rest of the input is given to a dense layer. A new model is the chaining of the couple [identity, dense layer] and of the pre-trained AMNWt model. This new model is then trained on all the experimental dataset. The output of the trained couple [identity, dense layer] is then given a input layer for cobra model.\n",
    "\n",
    "We use this idea on two pair of dataset. Fist on e_coli, we use iML1515_UB as simulated dataset and iML1515_EXP_UB as experimental dataset. Then on P.putida, we use IJN1463_10_UB as simulated dataset and IJN1463_EXP_UB_Anne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E_coli with iML1515 \n",
    "dataset_file_simulated = \"/Dataset/iML1515_UB_Anne.npz\"\n",
    "objective_simulated=['BIOMASS_Ec_iML1515_core_75p37M']\n",
    "dataset_file_experimental = \"/Dataset/iML1515_EXP_UB.npz\"\n",
    "objective_experimental=['BIOMASS_Ec_iML1515_core_75p37M']\n",
    "\n",
    "model_file_simulated = \"../models/AMNWt_iML1515_UB.keras\"\n",
    "\n",
    "batch_size = 7\n",
    "epochs = 100 \n",
    "seed = 10\n",
    "\n",
    "essential_medium_size = 28\n",
    "essential_medium_level = 2.2\n",
    "hidden_layer_size = 500\n",
    "\n",
    "cobra_model_file = \"/Dataset/iML1515_EXP_UB.xml\"\n",
    "objective = [\"BIOMASS_Ec_iML1515_core_75p37M\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P.putida with IJN1463\n",
    "dataset_file_simulated = \"/Dataset/IJN1463_10_UB.npz\"\n",
    "objective_simulated=['BIOMASS_KT2440_WT3']\n",
    "dataset_file_experimental = \"/Dataset/IJN1463_EXP_UB_Anne.npz\"\n",
    "objective_experimental=['BIOMASS_KT2440_WT3']\n",
    "\n",
    "model_file_simulated = \"../models/AMNWt_IJN1463_10_UB_no_scaling.keras\"\n",
    "\n",
    "batch_size = 7\n",
    "epochs = 20\n",
    "seed = 10\n",
    "\n",
    "essential_medium_size = 23\n",
    "essential_medium_level = 10\n",
    "hidden_layer_size = 500\n",
    "\n",
    "cobra_model_file = \"/Dataset/IJN1463_EXP_UB_Anne.xml\"\n",
    "objective = [\"BIOMASS_KT2440_WT3\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the experimental and simulated datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from amn.model.aMNWtModel import AMNWtModel\n",
    "\n",
    "tf.random.set_seed(seed)\n",
    "data_dir = \"../data\"\n",
    "\n",
    "model_simulated = AMNWtModel(dataset_file=data_dir + dataset_file_simulated, \n",
    "                   objective=objective_simulated,\n",
    "                   timestep=4,\n",
    "                   hidden_dim=50,\n",
    "                   verbose=True,\n",
    "                   )\n",
    "\n",
    "model_simulated.train_test_split(test_size=0.1, random_state=seed)\n",
    "model_simulated.preprocessing_for_specific_model()\n",
    "\n",
    "\n",
    "model_experimental = AMNWtModel(dataset_file=data_dir + dataset_file_experimental, \n",
    "                   objective=objective_experimental,\n",
    "                   timestep=4,\n",
    "                   hidden_dim=50,\n",
    "                   verbose=True,\n",
    "                   )\n",
    "\n",
    "model_experimental.train_test_split(test_size=0.1, random_state=seed)\n",
    "model_experimental.preprocessing_for_specific_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the pre-trained model on simulated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from amn.model.aMNWtModel import RNNCell\n",
    "from amn.tools import custom_loss\n",
    "\n",
    "loss = custom_loss(model_simulated.S, model_simulated.P_out, model_simulated.P_in)\n",
    "\n",
    "AMNWt_model = tf.keras.models.load_model(model_file_simulated, \n",
    "                                          custom_objects={\"RNNCell\":RNNCell,\n",
    "                                                          \"my_mse\":custom_loss(model_simulated.S, \n",
    "                                                                               model_simulated.P_out,\n",
    "                                                                               model_simulated.P_in)}\n",
    "                                          )\n",
    "\n",
    "print(\"R2 :\", model_simulated.R2(model_simulated.Y_train, AMNWt_model.predict(model_simulated.X_train)))\n",
    "print(\"Q2 :\", model_simulated.R2(model_simulated.Y_test, AMNWt_model.predict(model_simulated.X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a layer to old pre-trained model and fix model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model, Input, layers\n",
    "\n",
    "# Different layer of new model\n",
    "AMNWt_model.trainable = False\n",
    "layer_1 = layers.Dense(hidden_layer_size,\n",
    "                     activation='relu')\n",
    "layer_2 = layers.Dense(model_experimental.X.shape[1] - essential_medium_size,\n",
    "                     activation='relu')\n",
    "\n",
    "# split intput\n",
    "inputs = Input((model_experimental.X.shape[1]))\n",
    "input_dense = inputs[:,essential_medium_size:]  \n",
    "input_fixed = inputs[:,:essential_medium_size]\n",
    "\n",
    "# create the new model\n",
    "x = layer_2(layer_1(input_dense))\n",
    "y = AMNWt_model(tf.concat([input_fixed, x],1))\n",
    "\n",
    "new_model = Model(inputs=inputs, \n",
    "                  outputs=y)\n",
    "\n",
    "new_model.compile(optimizer='adam',\n",
    "              loss=loss,\n",
    "              metrics=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train new model on all experimental dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from amn.visualize import plot_regression\n",
    "\n",
    "# Train the new model\n",
    "X = model_experimental.X * essential_medium_level\n",
    "Y = np.concatenate((model_experimental.Y, np.zeros((len(model_experimental.Y),3))), axis=1)\n",
    "history = new_model.fit(X, Y, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "\n",
    "# Use it to predict all fluxes\n",
    "pred_all = new_model.predict(X)\n",
    "R_2 = model_simulated.R2(Y, pred_all)\n",
    "print(\"R² = \", R_2)\n",
    "\n",
    "# Results\n",
    "pred_growth_rate = tf.linalg.matmul(pred_all[:,:model_simulated.S.shape[1]], \n",
    "                        tf.transpose(np.float32(model_simulated.P_out))) \n",
    "true_growth_rate = Y[:,0]\n",
    "plot_regression(pred_growth_rate, \n",
    "                true_growth_rate, \"\", \"\",\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using cobra with output of the new_model as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the input\n",
    "X_dense = X[:,essential_medium_size:]  \n",
    "X_fixed = X[:,:essential_medium_size]\n",
    "\n",
    "# Use the dense layers to get the input fluxes for cobra\n",
    "x_output_dense = layer_2(layer_1(X_dense))\n",
    "V_in = tf.concat([X_fixed, x_output_dense],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cobra\n",
    "from sklearn.metrics import r2_score\n",
    "from amn.run_cobra import run_cobra\n",
    "\n",
    "\n",
    "\n",
    "cobra_model = cobra.io.read_sbml_model(data_dir + cobra_model_file)\n",
    "\n",
    "pred_cobra = []\n",
    "for i in range(V_in.shape[0]):\n",
    "    # Initialize all the reaction to 0\n",
    "    inf = {r.id: 0 for r in cobra_model.reactions}\n",
    "    # Add all the non-nul inputs for the entry i\n",
    "    for j in range(V_in.shape[1]):\n",
    "        inf[model_simulated.medium[j]] = float(V_in[i,j]) \n",
    "    result = run_cobra(cobra_model,objective,inf)\n",
    "\n",
    "    pred_cobra.append(result[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results\n",
    "R_2 = r2_score(true_growth_rate, pred_cobra)\n",
    "print(\"R² = \", R_2)\n",
    "plot_regression(pred_cobra, true_growth_rate, \"\", \"\",\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification (putida only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from amn.visualize import plot_classification\n",
    "plot_classification(pred_cobra, true_growth_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original dataset of Putida comes originally from the article : *High-quality genome-scale metabolic modelling of Pseudomonas putida highlights its broad metabolic capabilities. Nogales, J. et al., Environ. Microbiol. 22, 255–269 (2020).*\n",
    "\n",
    "In this article they explore alternative sources of carbon and nitrogen, testing the growth/no growth. The accuracy is then computed on all the dataset, and on the part of the dataset where they explores alternative source for carbon (resp. nitrogen)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from amn.tools import threshold_percentage_max\n",
    "\n",
    "# Finding nitrogen and carbon alternative source testing\n",
    "X_nitrogen = X[:,22] == 0 \n",
    "X_carbon = X[:,15] == 0\n",
    "nitrogen_index = [i for (i, bool) in enumerate(X_nitrogen) if bool]\n",
    "carbon_index = [i for (i, bool) in enumerate(X_carbon) if bool]\n",
    "\n",
    "# Threshold cobra prediction to obtain binary vector \n",
    "pred_cobra_binary = threshold_percentage_max(np.array(pred_cobra), 0.3)\n",
    "\n",
    "all_accuracy = accuracy_score(pred_cobra_binary, true_growth_rate)\n",
    "carbon_accuracy = accuracy_score(pred_cobra_binary[carbon_index] , true_growth_rate[carbon_index])\n",
    "nitrogen_accuracy = accuracy_score(pred_cobra_binary[nitrogen_index] , true_growth_rate[nitrogen_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from amn.visualize import plot_accuracies\n",
    "\n",
    "condition = [\"All\", \"Carbon\", \"Nitrogen\"]\n",
    "acc_fit_AMN = [all_accuracy, carbon_accuracy, nitrogen_accuracy]\n",
    "print(acc_fit_AMN)\n",
    "plot_accuracies(acc_fit_AMN, condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "condition = [\"All\", \"Carbon\", \"Nitrogen\"]\n",
    "acc_fit_AMN = [all_accuracy, carbon_accuracy, nitrogen_accuracy]\n",
    "# acc_fit_AMN = (all_accuracy, carbon_accuracy, nitrogen_accuracy)\n",
    "\n",
    "print(\"All accuracy : %.2f\\nCarbon : %.2f\\nNitrogen : %.2f\" %(all_accuracy, carbon_accuracy, nitrogen_accuracy))\n",
    "\n",
    "sns.set_theme(style='whitegrid', font='arial', font_scale=2, palette='colorblind')\n",
    "sns.barplot(x=condition, y=acc_fit_AMN, color=\"grey\")\n",
    "plt.yticks([0.8, 0.9, 1.00])\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim(0.8, 1)\n",
    "if False:\n",
    "    plt.savefig(\"Figure/Putida_accuracy_all_carbon_nitrogen\", format=\"png\", dpi=800, bbox_inches = 'tight')\n",
    "plt.show()\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AMN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
