{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on save and load of the custom keras model\n",
    "\n",
    "We create a model, train it and save it in a given directory. Then we load it again, check if the score are the same on the dataset, and check that we can train it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putida\n",
    "# dataset_file = \"/Dataset/IJN1463_10_UB.npz\"\n",
    "# objective=['BIOMASS_KT2440_WT3']\n",
    "# epoch = 20\n",
    "# batch_size = 30\n",
    "# uptake_max_index = None\n",
    "# model_file = \"/Models/AMNWt_IJN1463_10_UB.keras\"\n",
    "\n",
    "# E-coli\n",
    "dataset_file = \"/Dataset/iML1515_UB.npz\"\n",
    "objective=['BIOMASS_Ec_iML1515_core_75p37M']\n",
    "epoch = 10\n",
    "batch_size = 30\n",
    "uptake_max_index = None\n",
    "model_file = \"/AMNWt_iML1515_UB.keras\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of metabolites:  1877\n",
      "filtered measurements size:  1\n",
      "dataset file: ../data/Dataset/iML1515_UB.npz\n",
      "model type: AMNWt\n",
      "model medium bound: UB\n",
      "timestep: 4\n",
      "training set size (11000, 38) (11000, 1)\n",
      "nbr hidden layer: 1\n",
      "hidden layer size: 50\n",
      "activation function: relu\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from amn.model.aMNWtModel import AMNWtModel, RNNCell\n",
    "\n",
    "seed = 10\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "data_dir = \"../data\"\n",
    "model_dir = \"../models\"\n",
    "model_class = AMNWtModel\n",
    "\n",
    "# Create the model with dataset\n",
    "model = model_class(dataset_file=data_dir + dataset_file, \n",
    "                   objective=objective,\n",
    "                   timestep=4,\n",
    "                   hidden_dim=50,\n",
    "                   verbose=True)\n",
    "model.printout()\n",
    "\n",
    "# Preprocessing\n",
    "model.train_test_split(test_size=0.1, random_state=seed)\n",
    "model.preprocessing_for_specific_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-29 15:32:04.303615: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-29 15:32:04.305107: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2023-11-29 15:32:04.902238: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 : 0.9993539978754362\n",
      "Q2 : 0.9996111356698927\n"
     ]
    }
   ],
   "source": [
    "# Build and train the model\n",
    "AMNWt_model = model.build_model()\n",
    "history = AMNWt_model.fit(model.X_train, model.Y_train, epochs=epoch, batch_size=batch_size, verbose=0)\n",
    "\n",
    "print(\"R2 :\", model.R2(model.Y_train, AMNWt_model.predict(model.X_train)))\n",
    "print(\"Q2 :\", model.R2(model.Y_test, AMNWt_model.predict(model.X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the train AMNWt_model\n",
    "tf.keras.models.save_model(AMNWt_model,\n",
    "                           model_dir +model_file, \n",
    "                           overwrite=True, \n",
    "                           save_format=None, \n",
    "                           save_traces=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 : 0.9993539978754362\n",
      "Q2 : 0.9996111356698927\n"
     ]
    }
   ],
   "source": [
    "from amn.tools import custom_loss\n",
    "\n",
    "# Load the model\n",
    "AMNWt_model_ = tf.keras.models.load_model(model_dir +model_file, \n",
    "                                          custom_objects={\"RNNCell\":RNNCell,\n",
    "                                                          \"my_mse\":custom_loss(model.S, \n",
    "                                                                               model.P_out,\n",
    "                                                                               model.P_in)}\n",
    "                                          )\n",
    "\n",
    "print(\"R2 :\", model.R2(model.Y_train, AMNWt_model_.predict(model.X_train)))\n",
    "print(\"Q2 :\", model.R2(model.Y_test, AMNWt_model_.predict(model.X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 : 0.9991373357262987\n",
      "Q2 : 0.9994145691035303\n"
     ]
    }
   ],
   "source": [
    "# Train mode the model\n",
    "history = AMNWt_model_.fit(model.X_train, model.Y_train, epochs=epoch, batch_size=batch_size, verbose=0)\n",
    "print(\"R2 :\", model.R2(model.Y_train, AMNWt_model_.predict(model.X_train)))\n",
    "print(\"Q2 :\", model.R2(model.Y_test, AMNWt_model_.predict(model.X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annex : create a new model using the config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 : 0.9993539978754362\n",
      "Q2 : 0.9996111356698927\n"
     ]
    }
   ],
   "source": [
    "from amn.tools import custom_loss\n",
    "\n",
    "seed = 10\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# Recreate new model from config file First test on config.\n",
    "config = AMNWt_model.get_config()\n",
    "AMNWt_model_= tf.keras.Model.from_config(config, custom_objects={\"RNNCell\":RNNCell})\n",
    "my_mse = custom_loss(model.S, model.P_out,model.P_in)\n",
    "\n",
    "# Compile and train\n",
    "AMNWt_model_.compile(loss=my_mse,optimizer='adam',metrics=[my_mse])\n",
    "history = AMNWt_model_.fit(model.X_train, model.Y_train, epochs=epoch, batch_size=batch_size, verbose=0)\n",
    "\n",
    "print(\"R2 :\", model.R2(model.Y_train, AMNWt_model_.predict(model.X_train)))\n",
    "print(\"Q2 :\", model.R2(model.Y_test, AMNWt_model_.predict(model.X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AMN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
