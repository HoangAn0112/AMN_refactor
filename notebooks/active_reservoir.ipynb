{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import sys\n",
    "#sys.path.append('..\\\\AMN_refactor')\n",
    "import os\n",
    "import amn\n",
    "#os.getcwd()\n",
    "os.chdir(\"c:\\\\Users\\\\tnhoang\\\\Documents\\\\refactor_AMN\\\\AMN_refactor\")\n",
    "from scripts.build_dataset import generate_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generated \"medium_file\", which contains condition to simulated new data from experiment dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "file_name = 'iML1515_Paul_280.csv'\n",
    "save_name = 'Paul_media.csv'\n",
    "\n",
    "\n",
    "dataset_name = \"iML1515_Paul_280\"\n",
    "generation_file = \"config/dataset_generation.json\"\n",
    "data_dir = \"data\"\n",
    "generate_dataset(dataset_name,generation_file,data_dir,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E_coli of Paul \n",
    "dataset_file_simulated = \"/Dataset/iML1515_Paul_280.npz\"\n",
    "dataset_file_experimental = \"/Dataset/iML1515_Paul_EXP.npz\"\n",
    "objective = [\"BIOMASS_Ec_iML1515_core_75p37M\"]\n",
    "\n",
    "pretrained_model_name = \"AMNWt_Paul.keras\"\n",
    "cobra_model_file = \"/Dataset/iML1515_Paul_EXP.xml\"\n",
    "\n",
    "batch_size = 7\n",
    "epochs = 100 \n",
    "seed = 10\n",
    "\n",
    "essential_medium_size = 23\n",
    "essential_medium_level = 15\n",
    "hidden_layer_size = 500\n",
    "\n",
    "plot_figure_regression = \"figures_reservoir/reservoir_iML1515_Paul.png\"\n",
    "plot_figure_classification = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"../models/\"\n",
    "model_file_simulated = model_dir + pretrained_model_name\n",
    "\n",
    "# Unzip the model files\n",
    "from amn.archive import unzip_folders\n",
    "unzip_folders(model_dir)\n",
    "\n",
    "import os \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from amn.model.aMNWtModel import AMNWtModel\n",
    "\n",
    "tf.random.set_seed(seed)\n",
    "data_dir = \"../data\"\n",
    "\n",
    "model_simulated = AMNWtModel(dataset_file=data_dir + dataset_file_simulated, \n",
    "                   objective=objective,\n",
    "                   timestep=4,\n",
    "                   hidden_dim=50,\n",
    "                   verbose=True,\n",
    "                   )\n",
    "\n",
    "model_simulated.train_test_split(test_size=0.1, random_state=seed)\n",
    "model_simulated.preprocessing_for_specific_model()\n",
    "\n",
    "\n",
    "model_experimental = AMNWtModel(dataset_file=data_dir + dataset_file_experimental, \n",
    "                   objective=objective,\n",
    "                   timestep=4,\n",
    "                   hidden_dim=50,\n",
    "                   verbose=True,\n",
    "                   )\n",
    "\n",
    "model_experimental.train_test_split(test_size=0.1, random_state=seed)\n",
    "model_experimental.preprocessing_for_specific_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrain model\n",
    "from amn.model.aMNWtModel import RNNCell\n",
    "from amn.tools import custom_loss\n",
    "\n",
    "loss = custom_loss(model_simulated.S, model_simulated.P_out, model_simulated.P_in)\n",
    "\n",
    "AMNWt_model = tf.keras.models.load_model(model_file_simulated, \n",
    "                                          custom_objects={\"RNNCell\":RNNCell,\n",
    "                                                          \"my_mse\":custom_loss(model_simulated.S, \n",
    "                                                                               model_simulated.P_out,\n",
    "                                                                               model_simulated.P_in)}\n",
    "                                          )\n",
    "\n",
    "print(\"R2 :\", model_simulated.R2(model_simulated.Y_train, AMNWt_model.predict(model_simulated.X_train)))\n",
    "print(\"Q2 :\", model_simulated.R2(model_simulated.Y_test, AMNWt_model.predict(model_simulated.X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add dense layer and fixed weights\n",
    "\n",
    "from tensorflow.keras import Model, Input, layers\n",
    "\n",
    "# Different layer of new model\n",
    "AMNWt_model.trainable = False\n",
    "\n",
    "# split intput\n",
    "inputs = Input((model_experimental.X.shape[1]))\n",
    "input_dense = inputs[:,essential_medium_size:]  \n",
    "input_fixed = inputs[:,:essential_medium_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the combine block with experimental\n",
    "import numpy as np\n",
    "from amn.visualize import plot_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "# split intput\n",
    "inputs = Input((model_experimental.X.shape[1]))\n",
    "input_dense = inputs[:,essential_medium_size:]  \n",
    "input_fixed = inputs[:,:essential_medium_size]\n",
    "\n",
    "X = model_experimental.X * essential_medium_level\n",
    "Y = np.concatenate((model_experimental.Y, np.zeros((len(model_experimental.Y),3))), axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.5, random_state=42)\n",
    "\n",
    "# create and train ensemble of new model\n",
    "hidden_layer_sizes = [100, 200, 300, 400, 500] \n",
    "models_ensemble = []\n",
    "prediction_ensemble = []\n",
    "\n",
    "#ensemble \n",
    "for hidden_size in hidden_layer_sizes:\n",
    "    layer_1 = layers.Dense(hidden_size,\n",
    "                     activation='relu')\n",
    "    layer_2 = layers.Dense(model_experimental.X.shape[1] - essential_medium_size,\n",
    "                     activation='relu')\n",
    "    \n",
    "    x = layer_2(layer_1(input_dense))\n",
    "    y = AMNWt_model(tf.concat([input_fixed, x],1))\n",
    "    \n",
    "    new_model = Model(inputs=inputs, \n",
    "                    outputs=y)  \n",
    "\n",
    "    new_model.compile(optimizer='adam',\n",
    "                loss=loss,\n",
    "                metrics=None)\n",
    "    history = new_model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "    models_ensemble.append(new_model)\n",
    "\n",
    "    # Use it to predict all fluxes\n",
    "    pred_all = new_model.predict(X_test)\n",
    "    pred_growth_rate = tf.linalg.matmul(pred_all[:,:model_simulated.S.shape[1]], \n",
    "                        tf.transpose(np.float32(model_simulated.P_out))) \n",
    "    \n",
    "    prediction_ensemble.append([pred_growth_rate])\n",
    "    R_2 = model_simulated.R2(y_test, pred_all) # pred_all or pred_growth_rate\n",
    "    print(\"R² = \", R_2)\n",
    "\n",
    "# Results\n",
    "true_growth_rate = y_test[:,0]\n",
    "pred_gr_mean = np.mean(np.array(prediction_ensemble), axis = 1)\n",
    "pred_gr_std = np.std(np.array(prediction_ensemble), axis = 1)\n",
    "\n",
    "\n",
    "plot_regression(pred=pred_gr_mean,\n",
    "                true=true_growth_rate,\n",
    "                pred_label=\"\",\n",
    "                true_label=\"\",\n",
    "                title=\"\",\n",
    "                saving_file=None,\n",
    "                show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MC-Dropout\n",
    "n_predict = 50\n",
    "\n",
    "dropout_layer = layers.Dropout(0.2)  # Adding dropout layer with dropout rate of 0.2\n",
    "x = layer_1(input_dense)\n",
    "x = dropout_layer(x, training = True)  # Applying dropout after the first hidden layer\n",
    "x = layer_2(x)\n",
    "\n",
    "y = AMNWt_model(tf.concat([input_fixed, x],1))\n",
    "\n",
    "mc_model = Model(inputs=inputs, \n",
    "                outputs=y)  \n",
    "\n",
    "mc_model.compile(optimizer='adam',\n",
    "            loss=loss,\n",
    "            metrics=None)\n",
    "\n",
    "history = mc_model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "\n",
    "mc_prediction = []\n",
    "# Use it to predict all fluxes\n",
    "for i in range(n_predict):\n",
    "    pred = mc_model.predict(X_test)\n",
    "    pred_growth_rate_mc = tf.linalg.matmul(pred[:,:model_simulated.S.shape[1]], \n",
    "                    tf.transpose(np.float32(model_simulated.P_out))) \n",
    "    mc_prediction.append([pred_growth_rate_mc])\n",
    "\n",
    "pred_mc_mean = np.mean(np.array(mc_prediction), axis = 1)\n",
    "pred_mc_std = np.std(np.array(mc_prediction), axis = 1)\n",
    "\n",
    "R_2 = model_simulated.R2(y_test, pred_mc_mean)\n",
    "print(\"R² = \", R_2)\n",
    "\n",
    "\n",
    "plot_regression(pred=pred_mc_mean,\n",
    "                true=true_growth_rate,\n",
    "                pred_label=\"\",\n",
    "                true_label=\"\",\n",
    "                title=\"\",\n",
    "                saving_file=None,\n",
    "                show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot std from mcdrop-out compare to emsemble\n",
    "\n",
    "plot_regression(pred=pred_mc_mean,\n",
    "                true=pred_gr_mean,\n",
    "                pred_label=\"Monte-Carlo Dropout STD\",\n",
    "                true_label=\"Ensemble STD\",\n",
    "                title=\"\",\n",
    "                saving_file=None,\n",
    "                show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm with cobra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the input\n",
    "X_dense = X[:,essential_medium_size:]  \n",
    "X_fixed = X[:,:essential_medium_size]\n",
    "\n",
    "# Use the dense layers to get the input fluxes for cobra\n",
    "x_output_dense = layer_2(layer_1(X_dense))\n",
    "V_in = tf.concat([X_fixed, x_output_dense],1)\n",
    "\n",
    "\n",
    "import cobra\n",
    "from sklearn.metrics import r2_score\n",
    "from amn.run_cobra import run_cobra\n",
    "\n",
    "\n",
    "\n",
    "cobra_model = cobra.io.read_sbml_model(data_dir + cobra_model_file)\n",
    "\n",
    "pred_cobra = []\n",
    "for i in range(V_in.shape[0]):\n",
    "    # Initialize all the reaction to 0\n",
    "    inf = {r.id: 0 for r in cobra_model.reactions}\n",
    "    # Add all the non-nul inputs for the entry i\n",
    "    for j in range(V_in.shape[1]):\n",
    "        inf[model_simulated.medium[j]] = float(V_in[i,j]) \n",
    "    result = run_cobra(cobra_model,objective,inf)\n",
    "\n",
    "    pred_cobra.append(result[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results\n",
    "R_2 = r2_score(true_growth_rate, pred_cobra)\n",
    "print(\"R² = \", R_2)\n",
    "plot_regression(pred=pred_cobra,\n",
    "                true=true_growth_rate,\n",
    "                pred_label=\"\",\n",
    "                true_label=\"\",\n",
    "                title=\"\",\n",
    "                saving_file=plot_figure_regression,\n",
    "                show=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
