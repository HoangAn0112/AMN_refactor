{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model file name: ./Dataset_model/e_coli_core_UB_50\n",
      "reduced model: False\n",
      "medium file name: ./Dataset_input/e_coli_core\n",
      "medium bound: UB\n",
      "list of reactions in objective: ['BIOMASS_Ecoli_core_w_GAM']\n",
      "method: pFBA\n",
      "training size: 50\n",
      "list of medium reactions: 20\n",
      "list of medium levels: 20\n",
      "list of medium values: 20\n",
      "ratio of variable medium turned on: 0.5\n",
      "list of measured reactions: 154\n",
      "Stoichiometric matrix (72, 154)\n",
      "Boundary matrix from reactions to medium: (20, 154)\n",
      "Measurement matrix from reaction to measures: (154, 154)\n",
      "Reaction to metabolite matrix: (72, 154)\n",
      "Metabolite to reaction matrix: (154, 72)\n",
      "Training set X: (50, 20)\n",
      "Training set Y: (50, 154)\n",
      "S_int matrix ()\n",
      "S_ext matrix ()\n",
      "Q matrix ()\n",
      "P matrix ()\n",
      "b_int vector ()\n",
      "b_ext vector ()\n",
      "Sb matrix ()\n",
      "c vector ()\n",
      "---------------------------------------- model ----------------------------------------\n",
      "number of reactions:  154 154\n",
      "number of metabolites:  72\n",
      "filtered measurements size:  1\n",
      "training file: ./Dataset_model/e_coli_core_UB_50\n",
      "model type: AMN_Wt\n",
      "model scaler: 1.0\n",
      "model input dim: 0\n",
      "model output dim: 0\n",
      "model medium bound: UB\n",
      "timestep: 4\n",
      "training set size (50, 20) (50, 1)\n",
      "nbr hidden layer: 1\n",
      "hidden layer size: 50\n",
      "activation function: relu\n",
      "training epochs: 10\n",
      "training regression: True\n",
      "training learn rate: 0.01\n",
      "training droP_out: 0.25\n",
      "training batch size: 7\n",
      "training validation iter: 0\n",
      "training xfold: 5\n",
      "training early stopping: False\n",
      "---------------------------------------- train and evaluate ----------------------------------------\n",
      "WARNING:tensorflow:From /home/agiralt/anaconda3/envs/AMN/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:3633: sparse_mat_mul (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.linalg.matmul` instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-25 10:12:27.329569: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-25 10:12:27.331123: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2023-07-25 10:12:27.591331: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train = -25.47 test = -41.32 loss-train = 0.028367 loss-test = 0.027396\n",
      "train = -34.05 test = -21.94 loss-train = 0.023299 loss-test = 0.024118\n",
      "train = -25.56 test = -42.41 loss-train = 0.023264 loss-test = 0.022864\n",
      "train = -27.96 test = -18.93 loss-train = 0.034178 loss-test = 0.034799\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe4e8068310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "train = -27.78 test = -66.81 loss-train = 0.017664 loss-test = 0.018178\n",
      "---------------------------------------- printing cross-validation results ----------------------------------------\n",
      "Stats for e_coli_core_UB_50_AMN_Wt CPU-time 22.1117\n",
      "R2 = -28.1636 (+/- 3.1255) Constraint = 0.0254 (+/- 0.0056)\n",
      "Q2 = -38.2816 (+/- 17.2118) Constraint = 0.0255 (+/- 0.0055)\n",
      "---------------------------------------- evaluate model on test set ----------------------------------------\n",
      "training file: ./Dataset_model/e_coli_core_UB_50\n",
      "model type: AMN_Wt\n",
      "model scaler: 10.0\n",
      "model input dim: 4\n",
      "model output dim: 0\n",
      "model medium bound: UB\n",
      "timestep: 4\n",
      "training set size (50, 20) (50, 1)\n",
      "nbr hidden layer: 1\n",
      "hidden layer size: 50\n",
      "activation function: relu\n",
      "training epochs: 10\n",
      "training regression: True\n",
      "training learn rate: 0.01\n",
      "training droP_out: 0.25\n",
      "training batch size: 7\n",
      "training validation iter: 0\n",
      "training xfold: 5\n",
      "training early stopping: False\n",
      "Stats for Test set CPU-time 0.0718\n",
      "R2 = -47.8442 Constraint = 0.0338\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from simulatedDataset import SimulatedDataset\n",
    "from metabolicDataset2 import MetabolicDataset\n",
    "\n",
    "np.random.seed(seed=10) \n",
    "\n",
    "DIRECTORY = \"./\"\n",
    "cobra_name =  'e_coli_core_duplicated'  \n",
    "medium_name = 'e_coli_core'\n",
    "cobra_file = os.path.join(DIRECTORY,\"Dataset_input\",cobra_name)\n",
    "medium_file = os.path.join(DIRECTORY,\"Dataset_input\",medium_name)\n",
    "sample_size  = 50\n",
    "\n",
    "# Run cobra\n",
    "parameter = SimulatedDataset(cobra_name=cobra_file, \n",
    "                             medium_name=medium_file, \n",
    "                             medium_bound='UB',#'EB' \n",
    "                             method='pFBA',\n",
    "                             objective=[],\n",
    "                             measure=[],\n",
    "                             sample_size=sample_size)\n",
    "\n",
    "\n",
    "# parameter.get_simulated_data(sample_size=50) # ? Leaving objective and measure as empty lists sets the default objective reaction of the SBML model as the objective reaction value_med and the measure (Y) as this objective reaction.\n",
    "\n",
    "# Saving file\n",
    "training_file = os.path.join(DIRECTORY,\"Dataset_model\", medium_name+'_'+parameter.medium_bound+'_'+str(sample_size))\n",
    "parameter.save(training_file, reduce=False) # Reduce model\n",
    "\n",
    "# Load\n",
    "parameter = MetabolicDataset(training_file=training_file)\n",
    "parameter.printout()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from aMNWtModel import AMNWtModel\n",
    "from tools import printout\n",
    "\n",
    "DIRECTORY = './'\n",
    "SAVE_RESERVOIR = False\n",
    "\n",
    "seed = 10\n",
    "np.random.seed(seed=seed)  \n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# FBA simulated training set for E. coli core\n",
    "## (not working with M1 chips ). I don't understand :)\n",
    "# Create, train and evaluate AMN_Wt models with FBA simulated training set for E. coli core with upper bound (UB) or exact bound (EB) \n",
    "train_name = 'e_coli_core_UB_50' # e_coli_core_UB_50\n",
    "objective = ['BIOMASS_Ecoli_core_w_GAM']\n",
    "reservoir_name = train_name + \"_AMN_Wt\"\n",
    "training_file = os.path.join(DIRECTORY,'Dataset_model/',train_name)\n",
    "\n",
    "print(\"---------------------------------------- model ----------------------------------------\")\n",
    "\n",
    "model = AMNWtModel(training_file = training_file, \n",
    "                   objective=objective,  \n",
    "                   model_type='AMN_Wt', \n",
    "                   timestep =4,\n",
    "                   n_hidden = 1,\n",
    "                   hidden_dim = 50,\n",
    "                   scaler=True,\n",
    "                   train_rate=1e-2,\n",
    "                   epochs=10, \n",
    "                   xfold=5,\n",
    "                   verbose=True,\n",
    "                   batch_size=7)\n",
    "\n",
    "model.train_test_split(test_size=0.1, random_state=seed)\n",
    "model.printout()\n",
    "\n",
    "print(\"---------------------------------------- train and evaluate ----------------------------------------\")\n",
    "start_time = time.time()\n",
    "_, stats, _ = model.train_evaluate(verbose=False)\n",
    "reservoir = model\n",
    "delta_time = time.time() - start_time\n",
    "\n",
    "print(\"---------------------------------------- printing cross-validation results ----------------------------------------\")\n",
    "stats.printout(reservoir_name, delta_time)\n",
    "\n",
    "\n",
    "print(\"---------------------------------------- evaluate model on test set ----------------------------------------\")\n",
    "if SAVE_RESERVOIR:\n",
    "    reservoir_file = os.path.join(DIRECTORY,'Reservoir/',reservoir_name)\n",
    "    reservoir.save(reservoir_file)\n",
    "\n",
    "reservoir.printout()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "## Strange two first lines, investigate\n",
    "reservoir.X, reservoir.Y = model.X_test, model.Y_test\n",
    "X, Y = reservoir.model_input(model.X_test, model.Y_test, verbose=False)\n",
    "pred, obj, loss = reservoir.evaluate_model(X, Y, verbose=False)\n",
    "delta_time = time.time() - start_time\n",
    "printout('Test set', delta_time, obj, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model file name: ./Dataset_model/iML1515_EXP_UB\n",
      "reduced model: False\n",
      "medium file name: ./Dataset_input/iML1515_EXP\n",
      "medium bound: UB\n",
      "list of reactions in objective: ['BIOMASS_Ec_iML1515_core_75p37M']\n",
      "method: EXP\n",
      "training size: 110\n",
      "list of medium reactions: 38\n",
      "list of medium levels: 0\n",
      "list of medium values: 0\n",
      "ratio of variable medium turned on: 0\n",
      "list of measured reactions: 543\n",
      "Stoichiometric matrix (1080, 543)\n",
      "Boundary matrix from reactions to medium: (38, 543)\n",
      "Measurement matrix from reaction to measures: (543, 543)\n",
      "Reaction to metabolite matrix: (1080, 543)\n",
      "Metabolite to reaction matrix: (543, 1080)\n",
      "Training set X: (110, 38)\n",
      "Training set Y: (110, 1)\n",
      "S_int matrix ()\n",
      "S_ext matrix ()\n",
      "Q matrix ()\n",
      "P matrix ()\n",
      "b_int vector ()\n",
      "b_ext vector ()\n",
      "Sb matrix ()\n",
      "c vector ()\n",
      "---------------------------------------- model ----------------------------------------\n",
      "number of reactions:  543 1\n",
      "number of metabolites:  1080\n",
      "filtered measurements size:  1\n",
      "training file: ./Dataset_model/iML1515_EXP_UB\n",
      "model type: AMN_Wt\n",
      "model scaler: 1.0\n",
      "model input dim: 0\n",
      "model output dim: 0\n",
      "model medium bound: UB\n",
      "timestep: 4\n",
      "training set size (110, 38) (110, 1)\n",
      "nbr hidden layer: 1\n",
      "hidden layer size: 50\n",
      "activation function: relu\n",
      "training epochs: 10\n",
      "training regression: True\n",
      "training learn rate: 0.01\n",
      "training droP_out: 0.25\n",
      "training batch size: 7\n",
      "training validation iter: 0\n",
      "training xfold: 5\n",
      "training early stopping: False\n",
      "---------------------------------------- train and evaluate ----------------------------------------\n",
      "train = -518.07 test = -346.42 loss-train = 0.044226 loss-test = 0.044243\n",
      "train = -0.09 test = -0.13 loss-train = 0.002123 loss-test = 0.002107\n",
      "train = -0.05 test = -0.01 loss-train = 0.000436 loss-test = 0.000444\n",
      "train = -0.01 test = -0.10 loss-train = 0.000334 loss-test = 0.000333\n",
      "train = -1.48 test = -2.09 loss-train = 0.029051 loss-test = 0.029034\n",
      "---------------------------------------- printing cross-validation results ----------------------------------------\n",
      "Stats for iML1515_EXP_UB_AMN_Wt CPU-time 58.3947\n",
      "R2 = -103.9429 (+/- 207.0641) Constraint = 0.0152 (+/- 0.0181)\n",
      "Q2 = -69.7476 (+/- 138.3404) Constraint = 0.0152 (+/- 0.0181)\n",
      "---------------------------------------- evaluate model on test set ----------------------------------------\n",
      "training file: ./Dataset_model/iML1515_EXP_UB\n",
      "model type: AMN_Wt\n",
      "model scaler: 1\n",
      "model input dim: 4\n",
      "model output dim: 0\n",
      "model medium bound: UB\n",
      "timestep: 4\n",
      "training set size (110, 38) (110, 1)\n",
      "nbr hidden layer: 1\n",
      "hidden layer size: 50\n",
      "activation function: relu\n",
      "training epochs: 10\n",
      "training regression: True\n",
      "training learn rate: 0.01\n",
      "training droP_out: 0.25\n",
      "training batch size: 7\n",
      "training validation iter: 0\n",
      "training xfold: 5\n",
      "training early stopping: False\n",
      "Stats for Test set CPU-time 0.1363\n",
      "R2 = -0.5111 Constraint = 0.0004\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from metabolicDataset2 import MetabolicDataset\n",
    "from experimentalDataset import ExperimentalDataset\n",
    "\n",
    "np.random.seed(seed=10) \n",
    "\n",
    "DIRECTORY = \"./\"\n",
    "cobra_name =  'iML1515_EXP' # reduced iML1515 model  \n",
    "medium_name = 'iML1515_EXP'\n",
    "cobra_file = os.path.join(DIRECTORY,\"Dataset_input\",cobra_name)\n",
    "medium_file = os.path.join(DIRECTORY,\"Dataset_input\",medium_name)\n",
    "\n",
    "# Get data\n",
    "parameter = ExperimentalDataset(cobra_name=cobra_file, \n",
    "                             medium_name=medium_file, \n",
    "                             medium_bound='UB', \n",
    "                             medium_size=38, \n",
    "                             method='EXP',\n",
    "                             verbose=False)\n",
    "\n",
    "# Saving file\n",
    "training_file = os.path.join(DIRECTORY,\"Dataset_model\",medium_name+'_'+parameter.medium_bound)\n",
    "parameter.save(training_file, reduce=False) # Reduce model ## parameter.save(Directory)\n",
    "\n",
    "# Verifying\n",
    "parameter = MetabolicDataset(training_file)\n",
    "parameter.printout()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from aMNWtModel import AMNWtModel\n",
    "from tools import printout\n",
    "\n",
    "DIRECTORY = './'\n",
    "SAVE_RESERVOIR = False\n",
    "\n",
    "seed = 10\n",
    "np.random.seed(seed=seed)  \n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# FBA simulated training set for E. coli core\n",
    "## (not working with M1 chips ). I don't understand :)\n",
    "# Create, train and evaluate AMN_Wt models with FBA simulated training set for E. coli core with upper bound (UB) or exact bound (EB) \n",
    "train_name = 'iML1515_EXP_UB' # e_coli_core_EB\n",
    "objective = ['BIOMASS_Ec_iML1515_core_75p37M']\n",
    "reservoir_name = train_name + \"_AMN_Wt\"\n",
    "training_file = os.path.join(DIRECTORY,'Dataset_model/',train_name)\n",
    "\n",
    "print(\"---------------------------------------- model ----------------------------------------\")\n",
    "\n",
    "model = AMNWtModel(training_file = training_file, \n",
    "                   objective=objective,  \n",
    "                   model_type='AMN_Wt', \n",
    "                   timestep =4,\n",
    "                   n_hidden = 1,\n",
    "                   hidden_dim = 50,\n",
    "                   scaler=True,\n",
    "                   train_rate=1e-2,\n",
    "                   epochs=10, \n",
    "                   xfold=5,\n",
    "                   verbose=True,\n",
    "                   batch_size=7)\n",
    "\n",
    "model.train_test_split(test_size=0.1, random_state=seed)\n",
    "model.printout()\n",
    "\n",
    "print(\"---------------------------------------- train and evaluate ----------------------------------------\")\n",
    "start_time = time.time()\n",
    "_, stats, _ = model.train_evaluate(verbose=False)\n",
    "reservoir = model\n",
    "delta_time = time.time() - start_time\n",
    "\n",
    "print(\"---------------------------------------- printing cross-validation results ----------------------------------------\")\n",
    "stats.printout(reservoir_name, delta_time)\n",
    "\n",
    "\n",
    "print(\"---------------------------------------- evaluate model on test set ----------------------------------------\")\n",
    "if SAVE_RESERVOIR:\n",
    "    reservoir_file = os.path.join(DIRECTORY,'Reservoir/',reservoir_name)\n",
    "    reservoir.save(reservoir_file)\n",
    "\n",
    "reservoir.printout()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "## Strange two first lines, investigate\n",
    "reservoir.X, reservoir.Y = model.X_test, model.Y_test\n",
    "X, Y = reservoir.model_input(model.X_test, model.Y_test, verbose=False)\n",
    "pred, obj, loss = reservoir.evaluate_model(X, Y, verbose=False)\n",
    "delta_time = time.time() - start_time\n",
    "printout('Test set', delta_time, obj, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test dataset model generation\n",
    "This notebook is used to test the generation of data realized originally in the Build_dataset notebook. We give one example for each situation, simulated data and experimental data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "model file name: ./Dataset_model/e_coli_core_UB_50\n",
      "reduced model: False\n",
      "medium file name: ./Dataset_input/e_coli_core\n",
      "medium bound: UB\n",
      "list of reactions in objective: ['BIOMASS_Ecoli_core_w_GAM']\n",
      "method: pFBA\n",
      "training size: 50\n",
      "list of medium reactions: 20\n",
      "list of medium levels: 20\n",
      "list of medium values: 20\n",
      "ratio of variable medium turned on: 0.5\n",
      "list of measured reactions: 154\n",
      "Stoichiometric matrix (72, 154)\n",
      "Boundary matrix from reactions to medium: (20, 154)\n",
      "Measurement matrix from reaction to measures: (154, 154)\n",
      "Reaction to metabolite matrix: (72, 154)\n",
      "Metabolite to reaction matrix: (154, 72)\n",
      "Training set X: (50, 20)\n",
      "Training set Y: (50, 154)\n",
      "S_int matrix ()\n",
      "S_ext matrix ()\n",
      "Q matrix ()\n",
      "P matrix ()\n",
      "b_int vector ()\n",
      "b_ext vector ()\n",
      "Sb matrix ()\n",
      "c vector ()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from metabolicDataset import MetabolicDataset\n",
    "\n",
    "np.random.seed(seed=10) \n",
    "\n",
    "DIRECTORY = \"./\"\n",
    "cobra_name =  'e_coli_core_duplicated'  \n",
    "medium_name = 'e_coli_core'\n",
    "cobra_file = os.path.join(DIRECTORY,\"Dataset_input\",cobra_name)\n",
    "medium_file = os.path.join(DIRECTORY,\"Dataset_input\",medium_name)\n",
    "\n",
    "# Run cobra\n",
    "parameter = MetabolicDataset(cobra_name=cobra_file, \n",
    "                             medium_name=medium_file, \n",
    "                             medium_bound='UB',#'EB' \n",
    "                             method='pFBA',\n",
    "                             objective=[],\n",
    "                             measure=[])\n",
    "\n",
    "size  = 50\n",
    "parameter.get_simulated_data(sample_size=size) # ? Leaving objective and measure as empty lists sets the default objective reaction of the SBML model as the objective reaction value_med and the measure (Y) as this objective reaction.\n",
    "\n",
    "# Saving file\n",
    "training_name = medium_name+'_'+parameter.medium_bound+'_'+str(size)\n",
    "training_file = os.path.join(DIRECTORY,\"Dataset_model\",training_name)\n",
    "parameter.save(training_file, reduce=False) # Reduce model\n",
    "\n",
    "# Load\n",
    "parameter = MetabolicDataset(training_file=training_file)\n",
    "parameter.printout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------- model ----------------------------------------\n",
      "number of reactions:  154 154\n",
      "number of metabolites:  72\n",
      "filtered measurements size:  1\n",
      "training file: ./Dataset_model/e_coli_core_UB_50\n",
      "model type: AMN_Wt\n",
      "model scaler: 1.0\n",
      "model input dim: 0\n",
      "model output dim: 0\n",
      "model medium bound: UB\n",
      "timestep: 4\n",
      "training set size (50, 20) (50, 1)\n",
      "nbr hidden layer: 1\n",
      "hidden layer size: 50\n",
      "activation function: relu\n",
      "training epochs: 10\n",
      "training regression: True\n",
      "training learn rate: 0.01\n",
      "training droP_out: 0.25\n",
      "training batch size: 7\n",
      "training validation iter: 0\n",
      "training xfold: 5\n",
      "training early stopping: False\n",
      "---------------------------------------- train and evaluate ----------------------------------------\n",
      "WARNING:tensorflow:From /home/agiralt/anaconda3/envs/AMN/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:3633: sparse_mat_mul (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.linalg.matmul` instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-24 13:43:43.875370: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-24 13:43:43.877470: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2023-07-24 13:43:44.125029: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train = -25.47 test = -41.32 loss-train = 0.028367 loss-test = 0.027396\n",
      "train = -34.05 test = -21.94 loss-train = 0.023299 loss-test = 0.024118\n",
      "train = -25.56 test = -42.41 loss-train = 0.023264 loss-test = 0.022864\n",
      "train = -27.96 test = -18.93 loss-train = 0.034178 loss-test = 0.034799\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f1b210f5040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "train = -27.78 test = -66.81 loss-train = 0.017664 loss-test = 0.018178\n",
      "---------------------------------------- printing cross-validation results ----------------------------------------\n",
      "Stats for e_coli_core_UB_50_AMN_Wt CPU-time 20.0559\n",
      "R2 = -28.1636 (+/- 3.1255) Constraint = 0.0254 (+/- 0.0056)\n",
      "Q2 = -38.2816 (+/- 17.2118) Constraint = 0.0255 (+/- 0.0055)\n",
      "---------------------------------------- evaluate model on test set ----------------------------------------\n",
      "training file: ./Dataset_model/e_coli_core_UB_50\n",
      "model type: AMN_Wt\n",
      "model scaler: 10.0\n",
      "model input dim: 4\n",
      "model output dim: 0\n",
      "model medium bound: UB\n",
      "timestep: 4\n",
      "training set size (50, 20) (50, 1)\n",
      "nbr hidden layer: 1\n",
      "hidden layer size: 50\n",
      "activation function: relu\n",
      "training epochs: 10\n",
      "training regression: True\n",
      "training learn rate: 0.01\n",
      "training droP_out: 0.25\n",
      "training batch size: 7\n",
      "training validation iter: 0\n",
      "training xfold: 5\n",
      "training early stopping: False\n",
      "Stats for Test set CPU-time 0.0535\n",
      "R2 = -47.8442 Constraint = 0.0338\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from aMNWtModel import AMNWtModel\n",
    "from tools import printout\n",
    "\n",
    "DIRECTORY = './'\n",
    "SAVE_RESERVOIR = False\n",
    "\n",
    "seed = 10\n",
    "np.random.seed(seed=seed)  \n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# FBA simulated training set for E. coli core\n",
    "## (not working with M1 chips ). I don't understand :)\n",
    "# Create, train and evaluate AMN_Wt models with FBA simulated training set for E. coli core with upper bound (UB) or exact bound (EB) \n",
    "train_name = 'e_coli_core_UB_50' # e_coli_core_UB_50\n",
    "objective = ['BIOMASS_Ecoli_core_w_GAM']\n",
    "reservoir_name = train_name + \"_AMN_Wt\"\n",
    "training_file = os.path.join(DIRECTORY,'Dataset_model/',train_name)\n",
    "\n",
    "print(\"---------------------------------------- model ----------------------------------------\")\n",
    "\n",
    "model = AMNWtModel(training_file = training_file, \n",
    "                   objective=objective,  \n",
    "                   model_type='AMN_Wt', \n",
    "                   timestep =4,\n",
    "                   n_hidden = 1,\n",
    "                   hidden_dim = 50,\n",
    "                   scaler=True,\n",
    "                   train_rate=1e-2,\n",
    "                   epochs=10, \n",
    "                   xfold=5,\n",
    "                   verbose=True,\n",
    "                   batch_size=7)\n",
    "\n",
    "model.train_test_split(test_size=0.1, random_state=seed)\n",
    "model.printout()\n",
    "\n",
    "print(\"---------------------------------------- train and evaluate ----------------------------------------\")\n",
    "start_time = time.time()\n",
    "_, stats, _ = model.train_evaluate(verbose=False)\n",
    "reservoir = model\n",
    "delta_time = time.time() - start_time\n",
    "\n",
    "print(\"---------------------------------------- printing cross-validation results ----------------------------------------\")\n",
    "stats.printout(reservoir_name, delta_time)\n",
    "\n",
    "\n",
    "print(\"---------------------------------------- evaluate model on test set ----------------------------------------\")\n",
    "if SAVE_RESERVOIR:\n",
    "    reservoir_file = os.path.join(DIRECTORY,'Reservoir/',reservoir_name)\n",
    "    reservoir.save(reservoir_file)\n",
    "\n",
    "reservoir.printout()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "## Strange two first lines, investigate\n",
    "reservoir.X, reservoir.Y = model.X_test, model.Y_test\n",
    "X, Y = reservoir.model_input(model.X_test, model.Y_test, verbose=False)\n",
    "pred, obj, loss = reservoir.evaluate_model(X, Y, verbose=False)\n",
    "delta_time = time.time() - start_time\n",
    "printout('Test set', delta_time, obj, loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "model file name: ./Dataset_model/iML1515_EXP_UB\n",
      "reduced model: False\n",
      "medium file name: ./Dataset_input/iML1515_EXP\n",
      "medium bound: UB\n",
      "list of reactions in objective: ['BIOMASS_Ec_iML1515_core_75p37M']\n",
      "method: EXP\n",
      "training size: 110\n",
      "list of medium reactions: 38\n",
      "list of medium levels: 0\n",
      "list of medium values: 0\n",
      "ratio of variable medium turned on: 0\n",
      "list of measured reactions: 543\n",
      "Stoichiometric matrix (1080, 543)\n",
      "Boundary matrix from reactions to medium: (38, 543)\n",
      "Measurement matrix from reaction to measures: (543, 543)\n",
      "Reaction to metabolite matrix: (1080, 543)\n",
      "Metabolite to reaction matrix: (543, 1080)\n",
      "Training set X: (110, 38)\n",
      "Training set Y: (110, 1)\n",
      "S_int matrix ()\n",
      "S_ext matrix ()\n",
      "Q matrix ()\n",
      "P matrix ()\n",
      "b_int vector ()\n",
      "b_ext vector ()\n",
      "Sb matrix ()\n",
      "c vector ()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from metabolicDataset import MetabolicDataset\n",
    "\n",
    "np.random.seed(seed=10) \n",
    "\n",
    "DIRECTORY = \"./\"\n",
    "cobra_name =  'iML1515_EXP' # reduced iML1515 model  \n",
    "medium_name = 'iML1515_EXP'\n",
    "cobra_file = os.path.join(DIRECTORY,\"Dataset_input\",cobra_name)\n",
    "medium_file = os.path.join(DIRECTORY,\"Dataset_input\",medium_name)\n",
    "\n",
    "# Get data\n",
    "parameter = MetabolicDataset(cobra_name=cobra_file, \n",
    "                             medium_name=medium_file, \n",
    "                             medium_bound='UB', \n",
    "                             medium_size=38, \n",
    "                             method='EXP',\n",
    "                             verbose=False)\n",
    "\n",
    "# Saving file\n",
    "training_name = medium_name+'_'+parameter.medium_bound\n",
    "training_file = os.path.join(DIRECTORY,\"Dataset_model\",training_name)\n",
    "parameter.save(training_file, reduce=False) # Reduce model ## parameter.save(Directory)\n",
    "\n",
    "# Verifying\n",
    "parameter = MetabolicDataset(training_file)\n",
    "parameter.printout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------- model ----------------------------------------\n",
      "number of reactions:  543 1\n",
      "number of metabolites:  1080\n",
      "filtered measurements size:  1\n",
      "training file: ./Dataset_model/iML1515_EXP_UB\n",
      "model type: AMN_Wt\n",
      "model scaler: 1.0\n",
      "model input dim: 0\n",
      "model output dim: 0\n",
      "model medium bound: UB\n",
      "timestep: 4\n",
      "training set size (110, 38) (110, 1)\n",
      "nbr hidden layer: 1\n",
      "hidden layer size: 50\n",
      "activation function: relu\n",
      "training epochs: 10\n",
      "training regression: True\n",
      "training learn rate: 0.01\n",
      "training droP_out: 0.25\n",
      "training batch size: 7\n",
      "training validation iter: 0\n",
      "training xfold: 5\n",
      "training early stopping: False\n",
      "---------------------------------------- train and evaluate ----------------------------------------\n",
      "train = -518.07 test = -346.42 loss-train = 0.044226 loss-test = 0.044243\n",
      "train = -0.09 test = -0.13 loss-train = 0.002123 loss-test = 0.002107\n",
      "train = -0.05 test = -0.01 loss-train = 0.000436 loss-test = 0.000444\n",
      "train = -0.01 test = -0.10 loss-train = 0.000334 loss-test = 0.000333\n",
      "train = -1.48 test = -2.09 loss-train = 0.029051 loss-test = 0.029034\n",
      "---------------------------------------- printing cross-validation results ----------------------------------------\n",
      "Stats for iML1515_EXP_UB_AMN_Wt CPU-time 58.1615\n",
      "R2 = -103.9429 (+/- 207.0641) Constraint = 0.0152 (+/- 0.0181)\n",
      "Q2 = -69.7476 (+/- 138.3404) Constraint = 0.0152 (+/- 0.0181)\n",
      "---------------------------------------- evaluate model on test set ----------------------------------------\n",
      "training file: ./Dataset_model/iML1515_EXP_UB\n",
      "model type: AMN_Wt\n",
      "model scaler: 1\n",
      "model input dim: 4\n",
      "model output dim: 0\n",
      "model medium bound: UB\n",
      "timestep: 4\n",
      "training set size (110, 38) (110, 1)\n",
      "nbr hidden layer: 1\n",
      "hidden layer size: 50\n",
      "activation function: relu\n",
      "training epochs: 10\n",
      "training regression: True\n",
      "training learn rate: 0.01\n",
      "training droP_out: 0.25\n",
      "training batch size: 7\n",
      "training validation iter: 0\n",
      "training xfold: 5\n",
      "training early stopping: False\n",
      "Stats for Test set CPU-time 0.1239\n",
      "R2 = -0.5111 Constraint = 0.0004\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from aMNWtModel import AMNWtModel\n",
    "from tools import printout\n",
    "\n",
    "DIRECTORY = './'\n",
    "SAVE_RESERVOIR = False\n",
    "\n",
    "seed = 10\n",
    "np.random.seed(seed=seed)  \n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# FBA simulated training set for E. coli core\n",
    "## (not working with M1 chips ). I don't understand :)\n",
    "# Create, train and evaluate AMN_Wt models with FBA simulated training set for E. coli core with upper bound (UB) or exact bound (EB) \n",
    "train_name = 'iML1515_EXP_UB' # e_coli_core_EB\n",
    "objective = ['BIOMASS_Ec_iML1515_core_75p37M']\n",
    "reservoir_name = train_name + \"_AMN_Wt\"\n",
    "training_file = os.path.join(DIRECTORY,'Dataset_model/',train_name)\n",
    "\n",
    "print(\"---------------------------------------- model ----------------------------------------\")\n",
    "\n",
    "model = AMNWtModel(training_file = training_file, \n",
    "                   objective=objective,  \n",
    "                   model_type='AMN_Wt', \n",
    "                   timestep =4,\n",
    "                   n_hidden = 1,\n",
    "                   hidden_dim = 50,\n",
    "                   scaler=True,\n",
    "                   train_rate=1e-2,\n",
    "                   epochs=10, \n",
    "                   xfold=5,\n",
    "                   verbose=True,\n",
    "                   batch_size=7)\n",
    "\n",
    "model.train_test_split(test_size=0.1, random_state=seed)\n",
    "model.printout()\n",
    "\n",
    "print(\"---------------------------------------- train and evaluate ----------------------------------------\")\n",
    "start_time = time.time()\n",
    "_, stats, _ = model.train_evaluate(verbose=False)\n",
    "reservoir = model\n",
    "delta_time = time.time() - start_time\n",
    "\n",
    "print(\"---------------------------------------- printing cross-validation results ----------------------------------------\")\n",
    "stats.printout(reservoir_name, delta_time)\n",
    "\n",
    "\n",
    "print(\"---------------------------------------- evaluate model on test set ----------------------------------------\")\n",
    "if SAVE_RESERVOIR:\n",
    "    reservoir_file = os.path.join(DIRECTORY,'Reservoir/',reservoir_name)\n",
    "    reservoir.save(reservoir_file)\n",
    "\n",
    "reservoir.printout()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "## Strange two first lines, investigate\n",
    "reservoir.X, reservoir.Y = model.X_test, model.Y_test\n",
    "X, Y = reservoir.model_input(model.X_test, model.Y_test, verbose=False)\n",
    "pred, obj, loss = reservoir.evaluate_model(X, Y, verbose=False)\n",
    "delta_time = time.time() - start_time\n",
    "printout('Test set', delta_time, obj, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AMN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
