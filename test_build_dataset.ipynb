{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test dataset model generation\n",
    "This notebook is used to test the generation of data realized originally in the Build_dataset notebook. We give one example for each situation, simulated data and experimental data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model file name: ./Dataset_model/e_coli_core_EB_50\n",
      "reduced model: False\n",
      "medium file name: ./Dataset_input/e_coli_core\n",
      "medium bound: EB\n",
      "list of reactions in objective: ['BIOMASS_Ecoli_core_w_GAM']\n",
      "method: pFBA\n",
      "training size: 50\n",
      "list of medium reactions: 20\n",
      "list of medium levels: 20\n",
      "list of medium values: 20\n",
      "ratio of variable medium turned on: 0.5\n",
      "list of measured reactions: 154\n",
      "Stoichiometric matrix (72, 154)\n",
      "Boundary matrix from reactions to medium: (20, 154)\n",
      "Measurement matrix from reaction to measures: (154, 154)\n",
      "Reaction to metabolite matrix: (72, 154)\n",
      "Metabolite to reaction matrix: (154, 72)\n",
      "Training set X: (50, 20)\n",
      "Training set Y: (50, 154)\n",
      "S_int matrix (67, 154)\n",
      "S_ext matrix (154, 154)\n",
      "Q matrix (154, 67)\n",
      "P matrix (154, 154)\n",
      "b_int vector (50, 67)\n",
      "b_ext vector (154,)\n",
      "Sb matrix (154, 72)\n",
      "c vector (154,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from metabolicDataset import MetabolicDataset\n",
    "\n",
    "np.random.seed(seed=10) \n",
    "\n",
    "DIRECTORY = \"./\"\n",
    "cobra_name =  'e_coli_core_duplicated'  \n",
    "medium_name = 'e_coli_core'\n",
    "cobra_file = os.path.join(DIRECTORY,\"Dataset_input\",cobra_name)\n",
    "medium_file = os.path.join(DIRECTORY,\"Dataset_input\",medium_name)\n",
    "\n",
    "# Run cobra\n",
    "parameter = MetabolicDataset(cobra_name=cobra_file, \n",
    "                             medium_name=medium_file, \n",
    "                             medium_bound='UB',#'EB' \n",
    "                             method='pFBA',\n",
    "                             objective=[],\n",
    "                             measure=[])\n",
    "\n",
    "size  = 50\n",
    "parameter.get_simulated_data(sample_size=size) # ? Leaving objective and measure as empty lists sets the default objective reaction of the SBML model as the objective reaction value_med and the measure (Y) as this objective reaction.\n",
    "\n",
    "# Saving file\n",
    "training_name = medium_name+'_'+parameter.medium_bound+'_'+str(size)\n",
    "training_file = os.path.join(DIRECTORY,\"Dataset_model\",training_name)\n",
    "parameter.save(training_file, reduce=False) # Reduce model\n",
    "\n",
    "# Load\n",
    "parameter = MetabolicDataset(training_file=training_file)\n",
    "parameter.printout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------- model ----------------------------------------\n",
      "number of reactions:  154 154\n",
      "number of metabolites:  72\n",
      "filtered measurements size:  1\n",
      "training file: ./Dataset_model/e_coli_core_EB_50\n",
      "model type: AMN_Wt\n",
      "model scaler: 1.0\n",
      "model input dim: 0\n",
      "model output dim: 0\n",
      "model medium bound: EB\n",
      "timestep: 4\n",
      "training set size (50, 20) (50, 1)\n",
      "nbr hidden layer: 1\n",
      "hidden layer size: 50\n",
      "activation function: relu\n",
      "training epochs: 10\n",
      "training regression: True\n",
      "training learn rate: 0.01\n",
      "training droP_out: 0.25\n",
      "training batch size: 7\n",
      "training validation iter: 0\n",
      "training xfold: 5\n",
      "training early stopping: False\n",
      "---------------------------------------- train and evaluate ----------------------------------------\n",
      "WARNING:tensorflow:From /home/agiralt/anaconda3/envs/AMN/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:3633: sparse_mat_mul (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.linalg.matmul` instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-19 16:44:07.031974: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-19 16:44:07.033448: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2023-07-19 16:44:07.290248: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['rnn/rnn_cell/bias_Vi:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['rnn/rnn_cell/bias_Vi:0'] when minimizing the loss.\n",
      "train = -29.24 test = -48.17 loss-train = 0.025292 loss-test = 0.024604\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['rnn_1/rnn_cell_1/bias_Vi:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['rnn_1/rnn_cell_1/bias_Vi:0'] when minimizing the loss.\n",
      "train = -27.05 test = -17.57 loss-train = 0.038747 loss-test = 0.038635\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['rnn_2/rnn_cell_2/bias_Vi:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['rnn_2/rnn_cell_2/bias_Vi:0'] when minimizing the loss.\n",
      "train = -33.82 test = -54.88 loss-train = 0.007286 loss-test = 0.007257\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['rnn_3/rnn_cell_3/bias_Vi:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['rnn_3/rnn_cell_3/bias_Vi:0'] when minimizing the loss.\n",
      "train = -43.07 test = -28.59 loss-train = 0.004031 loss-test = 0.004059\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['rnn_4/rnn_cell_4/bias_Vi:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['rnn_4/rnn_cell_4/bias_Vi:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fced5f98dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "train = -26.02 test = -62.95 loss-train = 0.017256 loss-test = 0.017014\n",
      "---------------------------------------- printing cross-validation results ----------------------------------------\n",
      "Stats for e_coli_core_EB_50_AMN_Wt CPU-time 18.8442\n",
      "R2 = -31.8397 (+/- 6.2234) Constraint = 0.0185 (+/- 0.0126)\n",
      "Q2 = -42.4299 (+/- 16.8426) Constraint = 0.0183 (+/- 0.0125)\n",
      "---------------------------------------- evaluate model on test set ----------------------------------------\n",
      "training file: ./Dataset_model/e_coli_core_EB_50\n",
      "model type: AMN_Wt\n",
      "model scaler: 10.000000000007269\n",
      "model input dim: 4\n",
      "model output dim: 0\n",
      "model medium bound: EB\n",
      "timestep: 4\n",
      "training set size (50, 20) (50, 1)\n",
      "nbr hidden layer: 1\n",
      "hidden layer size: 50\n",
      "activation function: relu\n",
      "training epochs: 10\n",
      "training regression: True\n",
      "training learn rate: 0.01\n",
      "training droP_out: 0.25\n",
      "training batch size: 7\n",
      "training validation iter: 0\n",
      "training xfold: 5\n",
      "training early stopping: False\n",
      "Stats for Test set CPU-time 0.0552\n",
      "R2 = -46.1971 Constraint = 0.0392\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from aMNWtModel import AMNWtModel\n",
    "from tools import printout\n",
    "\n",
    "DIRECTORY = './'\n",
    "SAVE_RESERVOIR = False\n",
    "\n",
    "seed = 10\n",
    "np.random.seed(seed=seed)  \n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# FBA simulated training set for E. coli core\n",
    "## (not working with M1 chips ). I don't understand :)\n",
    "# Create, train and evaluate AMN_Wt models with FBA simulated training set for E. coli core with upper bound (UB) or exact bound (EB) \n",
    "train_name = 'e_coli_core_UB_50' # e_coli_core_UB_50\n",
    "objective = ['BIOMASS_Ecoli_core_w_GAM']\n",
    "reservoir_name = train_name + \"_AMN_Wt\"\n",
    "training_file = os.path.join(DIRECTORY,'Dataset_model/',train_name)\n",
    "\n",
    "print(\"---------------------------------------- model ----------------------------------------\")\n",
    "\n",
    "model = AMNWtModel(training_file = training_file, \n",
    "                   objective=objective,  \n",
    "                   model_type='AMN_Wt', \n",
    "                   timestep =4,\n",
    "                   n_hidden = 1,\n",
    "                   hidden_dim = 50,\n",
    "                   scaler=True,\n",
    "                   train_rate=1e-2,\n",
    "                   epochs=10, \n",
    "                   xfold=5,\n",
    "                   verbose=True,\n",
    "                   batch_size=7)\n",
    "\n",
    "model.train_test_split(test_size=0.1, random_state=seed)\n",
    "model.printout()\n",
    "\n",
    "print(\"---------------------------------------- train and evaluate ----------------------------------------\")\n",
    "start_time = time.time()\n",
    "_, stats, _ = model.train_evaluate(verbose=False)\n",
    "reservoir = model\n",
    "delta_time = time.time() - start_time\n",
    "\n",
    "print(\"---------------------------------------- printing cross-validation results ----------------------------------------\")\n",
    "stats.printout(reservoir_name, delta_time)\n",
    "\n",
    "\n",
    "print(\"---------------------------------------- evaluate model on test set ----------------------------------------\")\n",
    "if SAVE_RESERVOIR:\n",
    "    reservoir_file = os.path.join(DIRECTORY,'Reservoir/',reservoir_name)\n",
    "    reservoir.save(reservoir_file)\n",
    "\n",
    "reservoir.printout()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "## Strange two first lines, investigate\n",
    "reservoir.X, reservoir.Y = model.X_test, model.Y_test\n",
    "X, Y = reservoir.model_input(model.X_test, model.Y_test, verbose=False)\n",
    "pred, obj, loss = reservoir.evaluate_model(X, Y, verbose=False)\n",
    "delta_time = time.time() - start_time\n",
    "printout('Test set', delta_time, obj, loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model file name: ./Dataset_model/iML1515_EXP_UB\n",
      "reduced model: False\n",
      "medium file name: ./Dataset_input/iML1515_EXP\n",
      "medium bound: UB\n",
      "list of reactions in objective: ['BIOMASS_Ec_iML1515_core_75p37M']\n",
      "method: EXP\n",
      "training size: 110\n",
      "list of medium reactions: 38\n",
      "list of medium levels: 0\n",
      "list of medium values: 0\n",
      "ratio of variable medium turned on: 0\n",
      "list of measured reactions: 543\n",
      "Stoichiometric matrix (1080, 543)\n",
      "Boundary matrix from reactions to medium: (38, 543)\n",
      "Measurement matrix from reaction to measures: (543, 543)\n",
      "Reaction to metabolite matrix: (1080, 543)\n",
      "Metabolite to reaction matrix: (543, 1080)\n",
      "Training set X: (110, 38)\n",
      "Training set Y: (110, 1)\n",
      "S_int matrix (478, 543)\n",
      "S_ext matrix (543, 2703)\n",
      "Q matrix (543, 478)\n",
      "P matrix (543, 543)\n",
      "b_int vector (478,)\n",
      "b_ext vector (110, 2703)\n",
      "Sb matrix (543, 1080)\n",
      "c vector (543,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from metabolicDataset import MetabolicDataset\n",
    "\n",
    "np.random.seed(seed=10) \n",
    "\n",
    "DIRECTORY = \"./\"\n",
    "cobra_name =  'iML1515_EXP' # reduced iML1515 model  \n",
    "medium_name = 'iML1515_EXP'\n",
    "cobra_file = os.path.join(DIRECTORY,\"Dataset_input\",cobra_name)\n",
    "medium_file = os.path.join(DIRECTORY,\"Dataset_input\",medium_name)\n",
    "\n",
    "# Get data\n",
    "parameter = MetabolicDataset(cobra_name=cobra_file, \n",
    "                             medium_name=medium_file, \n",
    "                             medium_bound='UB', \n",
    "                             medium_size=38, \n",
    "                             method='EXP',\n",
    "                             verbose=False)\n",
    "\n",
    "# Saving file\n",
    "training_name = medium_name+'_'+parameter.medium_bound\n",
    "training_file = os.path.join(DIRECTORY,\"Dataset_model\",training_name)\n",
    "parameter.save(training_file, reduce=False) # Reduce model ## parameter.save(Directory)\n",
    "\n",
    "# Verifying\n",
    "parameter = MetabolicDataset(training_file)\n",
    "parameter.printout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------- model ----------------------------------------\n",
      "number of reactions:  543 1\n",
      "number of metabolites:  1080\n",
      "filtered measurements size:  1\n",
      "training file: ./Dataset_model/iML1515_EXP_UB\n",
      "model type: AMN_Wt\n",
      "model scaler: 1.0\n",
      "model input dim: 0\n",
      "model output dim: 0\n",
      "model medium bound: UB\n",
      "timestep: 4\n",
      "training set size (110, 38) (110, 1)\n",
      "nbr hidden layer: 1\n",
      "hidden layer size: 50\n",
      "activation function: relu\n",
      "training epochs: 10\n",
      "training regression: True\n",
      "training learn rate: 0.01\n",
      "training droP_out: 0.25\n",
      "training batch size: 7\n",
      "training validation iter: 0\n",
      "training xfold: 5\n",
      "training early stopping: False\n",
      "---------------------------------------- train and evaluate ----------------------------------------\n",
      "train = -518.07 test = -346.42 loss-train = 0.044226 loss-test = 0.044243\n",
      "train = -0.09 test = -0.13 loss-train = 0.002123 loss-test = 0.002107\n",
      "train = -0.05 test = -0.01 loss-train = 0.000436 loss-test = 0.000444\n",
      "train = -0.01 test = -0.10 loss-train = 0.000334 loss-test = 0.000333\n",
      "train = -1.48 test = -2.09 loss-train = 0.029051 loss-test = 0.029034\n",
      "---------------------------------------- printing cross-validation results ----------------------------------------\n",
      "Stats for iML1515_EXP_UB_AMN_Wt CPU-time 72.7545\n",
      "R2 = -103.9429 (+/- 207.0641) Constraint = 0.0152 (+/- 0.0181)\n",
      "Q2 = -69.7476 (+/- 138.3404) Constraint = 0.0152 (+/- 0.0181)\n",
      "---------------------------------------- evaluate model on test set ----------------------------------------\n",
      "training file: ./Dataset_model/iML1515_EXP_UB\n",
      "model type: AMN_Wt\n",
      "model scaler: 1\n",
      "model input dim: 4\n",
      "model output dim: 0\n",
      "model medium bound: UB\n",
      "timestep: 4\n",
      "training set size (110, 38) (110, 1)\n",
      "nbr hidden layer: 1\n",
      "hidden layer size: 50\n",
      "activation function: relu\n",
      "training epochs: 10\n",
      "training regression: True\n",
      "training learn rate: 0.01\n",
      "training droP_out: 0.25\n",
      "training batch size: 7\n",
      "training validation iter: 0\n",
      "training xfold: 5\n",
      "training early stopping: False\n",
      "Stats for Test set CPU-time 0.1079\n",
      "R2 = -0.5111 Constraint = 0.0004\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from aMNWtModel import AMNWtModel\n",
    "from tools import printout\n",
    "\n",
    "DIRECTORY = './'\n",
    "SAVE_RESERVOIR = False\n",
    "\n",
    "seed = 10\n",
    "np.random.seed(seed=seed)  \n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# FBA simulated training set for E. coli core\n",
    "## (not working with M1 chips ). I don't understand :)\n",
    "# Create, train and evaluate AMN_Wt models with FBA simulated training set for E. coli core with upper bound (UB) or exact bound (EB) \n",
    "train_name = 'iML1515_EXP_UB' # e_coli_core_EB\n",
    "objective = ['BIOMASS_Ec_iML1515_core_75p37M']\n",
    "reservoir_name = train_name + \"_AMN_Wt\"\n",
    "training_file = os.path.join(DIRECTORY,'Dataset_model/',train_name)\n",
    "\n",
    "print(\"---------------------------------------- model ----------------------------------------\")\n",
    "\n",
    "model = AMNWtModel(training_file = training_file, \n",
    "                   objective=objective,  \n",
    "                   model_type='AMN_Wt', \n",
    "                   timestep =4,\n",
    "                   n_hidden = 1,\n",
    "                   hidden_dim = 50,\n",
    "                   scaler=True,\n",
    "                   train_rate=1e-2,\n",
    "                   epochs=10, \n",
    "                   xfold=5,\n",
    "                   verbose=True,\n",
    "                   batch_size=7)\n",
    "\n",
    "model.train_test_split(test_size=0.1, random_state=seed)\n",
    "model.printout()\n",
    "\n",
    "print(\"---------------------------------------- train and evaluate ----------------------------------------\")\n",
    "start_time = time.time()\n",
    "_, stats, _ = model.train_evaluate(verbose=False)\n",
    "reservoir = model\n",
    "delta_time = time.time() - start_time\n",
    "\n",
    "print(\"---------------------------------------- printing cross-validation results ----------------------------------------\")\n",
    "stats.printout(reservoir_name, delta_time)\n",
    "\n",
    "\n",
    "print(\"---------------------------------------- evaluate model on test set ----------------------------------------\")\n",
    "if SAVE_RESERVOIR:\n",
    "    reservoir_file = os.path.join(DIRECTORY,'Reservoir/',reservoir_name)\n",
    "    reservoir.save(reservoir_file)\n",
    "\n",
    "reservoir.printout()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "## Strange two first lines, investigate\n",
    "reservoir.X, reservoir.Y = model.X_test, model.Y_test\n",
    "X, Y = reservoir.model_input(model.X_test, model.Y_test, verbose=False)\n",
    "pred, obj, loss = reservoir.evaluate_model(X, Y, verbose=False)\n",
    "delta_time = time.time() - start_time\n",
    "printout('Test set', delta_time, obj, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cobra utilities and stoichiometric derived matrices\n",
    "def get_index_from_id(name,L):\n",
    "    # Return index in L of id name\n",
    "    for i in range(len(L)):\n",
    "        if L[i].id == name:\n",
    "            return i\n",
    "    return -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "parameter.model.reactions[0]\n",
    "\n",
    "for i in range(len(parameter.model.reactions)):\n",
    "    if parameter.model.reactions[i].id == \"OMPDC\":\n",
    "        print(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OMPDC_reverse_45ba1\n"
     ]
    }
   ],
   "source": [
    "for r in parameter.model.reactions:\n",
    "    if r.id == \"OMPDC\":\n",
    "        print(r.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_from_id(name,L):\n",
    "    # Return index in L of id name\n",
    "    for i in range(len(L)):\n",
    "        if L[i].id == name:\n",
    "            return i\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = parameter.medium[5]\n",
    "L = parameter.model.reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_index_from_id(name,L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L.index(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for rid in self.medium:\n",
    "    j = get_index_from_id(rid, self.model.reactions)\n",
    "    X[:,i] = Y[:,j] \n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "EX_pi_e_i\n",
      "1\n",
      "EX_co2_e_i\n",
      "2\n",
      "EX_fe3_e_i\n",
      "3\n",
      "EX_h_e_i\n",
      "4\n",
      "EX_mn2_e_i\n",
      "5\n",
      "EX_fe2_e_i\n",
      "6\n",
      "EX_zn2_e_i\n",
      "7\n",
      "EX_mg2_e_i\n",
      "8\n",
      "EX_ca2_e_i\n",
      "9\n",
      "EX_ni2_e_i\n",
      "10\n",
      "EX_cu2_e_i\n",
      "11\n",
      "EX_sel_e_i\n",
      "12\n",
      "EX_cobalt2_e_i\n",
      "13\n",
      "EX_h2o_e_i\n",
      "14\n",
      "EX_mobd_e_i\n",
      "15\n",
      "EX_so4_e_i\n",
      "16\n",
      "EX_nh4_e_i\n",
      "17\n",
      "EX_k_e_i\n",
      "18\n",
      "EX_na1_e_i\n",
      "19\n",
      "EX_cl_e_i\n",
      "20\n",
      "EX_o2_e_i\n",
      "21\n",
      "EX_tungs_e_i\n",
      "22\n",
      "EX_slnt_e_i\n",
      "23\n",
      "EX_glyc_e_i\n",
      "24\n",
      "EX_ala__L_e_i\n",
      "25\n",
      "EX_pro__L_e_i\n",
      "26\n",
      "EX_thr__L_e_i\n",
      "27\n",
      "EX_gly_e_i\n",
      "28\n",
      "EX_rib__D_e_i\n",
      "29\n",
      "EX_malt_e_i\n",
      "30\n",
      "EX_melib_e_i\n",
      "31\n",
      "EX_tre_e_i\n",
      "32\n",
      "EX_fru_e_i\n",
      "33\n",
      "EX_gal_e_i\n",
      "34\n",
      "EX_ac_e_i\n",
      "35\n",
      "EX_lac__D_e_i\n",
      "36\n",
      "EX_succ_e_i\n",
      "37\n",
      "EX_pyr_e_i\n"
     ]
    }
   ],
   "source": [
    "for i,j in enumerate(parameter.medium):\n",
    "    print(i)\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['EX_pi_e_i', 'EX_co2_e_i', 'EX_fe3_e_i', 'EX_h_e_i', 'EX_mn2_e_i',\n",
       "       'EX_fe2_e_i', 'EX_zn2_e_i', 'EX_mg2_e_i', 'EX_ca2_e_i',\n",
       "       'EX_ni2_e_i', 'EX_cu2_e_i', 'EX_sel_e_i', 'EX_cobalt2_e_i',\n",
       "       'EX_h2o_e_i', 'EX_mobd_e_i', 'EX_so4_e_i', 'EX_nh4_e_i',\n",
       "       'EX_k_e_i', 'EX_na1_e_i', 'EX_cl_e_i', 'EX_o2_e_i', 'EX_tungs_e_i',\n",
       "       'EX_slnt_e_i', 'EX_glyc_e_i', 'EX_ala__L_e_i', 'EX_pro__L_e_i',\n",
       "       'EX_thr__L_e_i', 'EX_gly_e_i', 'EX_rib__D_e_i', 'EX_malt_e_i',\n",
       "       'EX_melib_e_i', 'EX_tre_e_i', 'EX_fru_e_i', 'EX_gal_e_i',\n",
       "       'EX_ac_e_i', 'EX_lac__D_e_i', 'EX_succ_e_i', 'EX_pyr_e_i'],\n",
       "      dtype='<U14')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter.medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AMN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
