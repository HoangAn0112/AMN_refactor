{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AMN-Wt on *E. coli* core FBA simulated training set\n",
    "This code help us to change the code of the project. It allows us to check that nothing changes while refactoring.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------- model ----------------------------------------\n",
      "number of reactions:  154 154\n",
      "number of metabolites:  72\n",
      "filtered measurements size:  1\n",
      "training file: ./Dataset_model/e_coli_core_UB\n",
      "model type: AMN_Wt\n",
      "model scaler: 1.0\n",
      "model input dim: 0\n",
      "model output dim: 0\n",
      "model medium bound: UB\n",
      "timestep: 4\n",
      "training set size (1000, 20) (1000, 1)\n",
      "nbr hidden layer: 1\n",
      "hidden layer size: 50\n",
      "activation function: relu\n",
      "training epochs: 20\n",
      "training regression: True\n",
      "training learn rate: 0.01\n",
      "training droP_out: 0.25\n",
      "training batch size: 7\n",
      "training validation iter: 0\n",
      "training xfold: 5\n",
      "training early stopping: False\n",
      "---------------------------------------- train and evaluate ----------------------------------------\n",
      "WARNING:tensorflow:From /home/agiralt/anaconda3/envs/AMN/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:3633: sparse_mat_mul (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.linalg.matmul` instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-20 14:43:30.185082: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-20 14:43:30.186659: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2023-04-20 14:43:30.645454: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train = 0.95 test = 0.96 loss-train = 0.004603 loss-test = 0.004677\n",
      "train = 0.96 test = 0.96 loss-train = 0.004758 loss-test = 0.004760\n",
      "train = 0.94 test = 0.93 loss-train = 0.004356 loss-test = 0.004264\n",
      "train = 0.95 test = 0.94 loss-train = 0.004296 loss-test = 0.004455\n",
      "train = 0.97 test = 0.96 loss-train = 0.004050 loss-test = 0.003941\n",
      "---------------------------------------- printing cross-validation results ----------------------------------------\n",
      "Stats for e_coli_core_UB_AMN_Wt CPU-time 174.5725\n",
      "R2 = 0.9514 (+/- 0.0108) Constraint = 0.0044 (+/- 0.0002)\n",
      "Q2 = 0.9509 (+/- 0.0114) Constraint = 0.0044 (+/- 0.0003)\n",
      "---------------------------------------- evaluate model on test set ----------------------------------------\n",
      "training file: ./Dataset_model/e_coli_core_UB\n",
      "model type: AMN_Wt\n",
      "model scaler: 10.0\n",
      "model input dim: 4\n",
      "model output dim: 0\n",
      "model medium bound: UB\n",
      "timestep: 4\n",
      "training set size (1000, 20) (1000, 1)\n",
      "nbr hidden layer: 1\n",
      "hidden layer size: 50\n",
      "activation function: relu\n",
      "training epochs: 20\n",
      "training regression: True\n",
      "training learn rate: 0.01\n",
      "training droP_out: 0.25\n",
      "training batch size: 7\n",
      "training validation iter: 0\n",
      "training xfold: 5\n",
      "training early stopping: False\n",
      "Stats for Test set CPU-time 0.1364\n",
      "R2 = 0.9649 Constraint = 0.0041\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from aMNWtModel import AMNWtModel\n",
    "from tools import printout\n",
    "\n",
    "DIRECTORY = './'\n",
    "SAVE_RESERVOIR = False\n",
    "\n",
    "seed = 10\n",
    "np.random.seed(seed=seed)  \n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "\n",
    "## (not working with M1 chips ). I don't understand :)\n",
    "# Create, train and evaluate AMN_Wt models with FBA simulated training set for E. coli core with upper bound (UB) or exact bound (EB) \n",
    "train_name = 'e_coli_core_UB' # e_coli_core_EB\n",
    "reservoir_name = train_name + \"_AMN_Wt\"\n",
    "training_file = os.path.join(DIRECTORY,'Dataset_model/',train_name)\n",
    "\n",
    "print(\"---------------------------------------- model ----------------------------------------\")\n",
    "model = AMNWtModel(training_file = training_file, \n",
    "                   objective=['BIOMASS_Ecoli_core_w_GAM'],  \n",
    "                   model_type='AMN_Wt', \n",
    "                   timestep =4,\n",
    "                   n_hidden = 1,\n",
    "                   hidden_dim = 50,\n",
    "                   scaler=True,\n",
    "                   train_rate=1e-2,\n",
    "                   epochs=20, \n",
    "                   xfold=5,\n",
    "                   verbose=True,\n",
    "                   batch_size=7)\n",
    "\n",
    "model.train_test_split(test_size=0.1, random_state=seed)\n",
    "model.printout()\n",
    "\n",
    "print(\"---------------------------------------- train and evaluate ----------------------------------------\")\n",
    "start_time = time.time()\n",
    "_, stats, _ = model.train_evaluate(verbose=False)\n",
    "reservoir = model\n",
    "delta_time = time.time() - start_time\n",
    "\n",
    "print(\"---------------------------------------- printing cross-validation results ----------------------------------------\")\n",
    "stats.printout(reservoir_name, delta_time)\n",
    "\n",
    "\n",
    "print(\"---------------------------------------- evaluate model on test set ----------------------------------------\")\n",
    "if SAVE_RESERVOIR:\n",
    "    reservoir_file = os.path.join(DIRECTORY,'Reservoir/',reservoir_name)\n",
    "    reservoir.save(reservoir_file)\n",
    "\n",
    "reservoir.printout()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "## Strange two first lines, investigate\n",
    "reservoir.X, reservoir.Y = model.X_test, model.Y_test\n",
    "X, Y = reservoir.model_input(model.X_test, model.Y_test, verbose=False)\n",
    "pred, obj, loss = reservoir.evaluate_model(X, Y, verbose=False)\n",
    "delta_time = time.time() - start_time\n",
    "printout('Test set', delta_time, obj, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('AMN')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3f11f5a114d66dd6718bb47b797cd3b721e1258f0329fa1cbf3393b6a696811f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
